{
    "__type__": "Deck",
    "children": [
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "42773030-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "4277329c-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "220px-Lipschitz_Visualisierung.gif",
                "300px-ConvexFunction.svg.png",
                "image001.png"
            ],
            "name": "calculus",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What is local linearity in relation to the Jacobian matrix?",
                        "<div>The Jacobian \\(J\\) of a nonlinear function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m \\) describes the local linear transformation.</div><div><div><br></div></div><div>If we zoom in close enough on a point that has a non linear transformation being applied to it the area around that point locally seems as if it has been transformed linearly.<br></div>"
                    ],
                    "guid": "v/r+DcIXpp",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do you determine if a function is convex?",
                        "A function is convex if the line segment between any two points on the graph of the function lies above or on the graph.<div><br></div><div><img src=\"300px-ConvexFunction.svg.png\"><br></div><div><br></div><div>Can also be said that for a twice differentiable function of a single variable, if the second derivative is always greater than or equal to zero for its entire domain then the function is convex<br></div>"
                    ],
                    "guid": "MSy+jp=m.9",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is Newton's Method?",
                        "<div>If \\(x_{n}\\) is an approximation to a solution of \\(f(x)=0\\) and if \\(f^{\\prime}\\left(x_{n}\\right) \\neq 0\\) the next approximation is given by,<br></div><div><br></div><div>\\(x_{n+1}=x_{n}-\\frac{f\\left(x_{n}\\right)}{f^{\\prime}\\left(x_{n}\\right)}\\)<br></div><div><div><br></div><div><img src=\"image001.png\"><br></div><div><br></div><div><br></div></div>"
                    ],
                    "guid": "y}K_}/#@Cb",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "When do stationary/critical points occur?",
                        "Stationary Points: Where \\(f^{\\prime}(x)=0\\)<div><br></div>"
                    ],
                    "guid": "Dkcx.3F=me",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How can the second order derivative tell us how well gradient descent will perform?",
                        "We can make a second-order Taylor series approximation to the function f(x) around current point&nbsp;\\(\\boldsymbol{x}^{(0)}\\)<div><br></div><div>The new point&nbsp;\\(\\boldsymbol{x}\\) will be given by \\(\\boldsymbol{x}^{(0)}-\\epsilon \\boldsymbol{g}\\)&nbsp; which we can substitute into our taylor series approximation<br><div><br></div><div>\\(f\\left(\\boldsymbol{x}^{(0)}-\\epsilon \\boldsymbol{g}\\right) \\approx f\\left(\\boldsymbol{x}^{(0)}\\right)-\\epsilon \\boldsymbol{g}^{\\top} \\boldsymbol{g}+\\frac{1}{2} \\epsilon^{2} \\boldsymbol{g}^{\\top} \\boldsymbol{H} \\boldsymbol{g}\\)<br></div></div>"
                    ],
                    "guid": "v#J@`OS8mX",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "marked"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How can the Hessian be used for a second derivative test?",
                        "For a function of multiple dimensions.<div><br></div><div>Perform eigendecomposition, and examine the eigenvalues.</div><div><br></div><div>Local Minimum: If Hessian is Positive Definite (all eigenvalues &gt; 0)</div><div>Local Maximum: If Hessian is Negative Definite (all eigenvalues &lt; 0)</div><div>Saddle Point: If one eigenvalue is positive and at least one eigenvalue is negative</div><div>Inconclusive: whenever all the nonzero eigenvalues have the same sign but at least one eigenvalue is zero</div><div><div><br></div></div>"
                    ],
                    "guid": "uhuuKhyK()",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is a Lipschitz continuous function?",
                        "A function f, whose rate of change is bound by a&nbsp;Lipschitz constant \\(\\mathcal{L}:\\)<div><br></div><div>\\(\\forall \\boldsymbol{x}, \\forall \\boldsymbol{y},|f(\\boldsymbol{x})-f(\\boldsymbol{y})| \\leq \\mathcal{L}\\|\\boldsymbol{x}-\\boldsymbol{y}\\|_{2}\\)<br></div><div><br></div><div><div>This property is useful because it enables us to quantify our assumption that a small change in the input made by an algorithm&nbsp;will have&nbsp;a small change in the output.</div></div><div><br></div><div><img src=\"220px-Lipschitz_Visualisierung.gif\"><br></div><div><br></div><div>For a Lipschitz continuous function, there exists a double cone (white) whose origin can be moved along the graph so that it always stays outside the double cone<br></div>"
                    ],
                    "guid": "oB,mwCaDWz",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do you predict the optimal step size for steepest descent?",
                        "\\(\\epsilon^{*}=\\frac{\\boldsymbol{g}^{\\top} \\boldsymbol{g}}{\\boldsymbol{g}^{\\top} \\boldsymbol{H} \\boldsymbol{g}}\\)<div><br></div><div>Numerato: that big gradients speed you up</div><div>Denominato: big eigenvalues slow you down if you align with their eigenvectors</div>"
                    ],
                    "guid": "I`6ccUB{dq",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Write down the first 3 terms of the Taylor series approximation",
                        "<div>\\( f(x) = f(x_0) + (x - x_0) f'(x) + \\frac{1}{2} \\left( x-x_0 \\right) ^2 f''(x) + \\mathcal{O}\\left((x-x_0)^3\\right) \\)</div><div><br></div><div>\\( f(\\vec{x}) = f(\\vec{x}_0) + (\\vec{x} - \\vec{x}_0)^\\intercal g(\\vec{x}_0) + (\\vec{x} - \\vec{x}_0)^\\intercal H(\\vec{x}_0)&nbsp; (\\vec{x} - \\vec{x}_0) + ... \\)</div>"
                    ],
                    "guid": "j.3zW26:T!",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "\\(\\frac{d}{d x}(\\cos x)\\)",
                        "- sin x"
                    ],
                    "guid": "eRQ[mA[8FW",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "\\(\\frac{d}{d x}(\\sec x)\\)",
                        "\\(\\sec x \\tan x\\)"
                    ],
                    "guid": "y(+Is}a[3p",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "\\(\\frac{d}{d x}\\left(a^{x}\\right)\\)",
                        "\\(a^{x} \\ln (a)\\)"
                    ],
                    "guid": "fs0Dm(411Q",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "\\(\\frac{d}{d x}\\left(\\log _{a}(x)\\right)\\)",
                        "\\(\\frac{1}{x \\ln a}\\)"
                    ],
                    "guid": "l<8GW</gtr",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "\\(\\int \\sin x d x\\)",
                        "\\(-\\cos x+c\\)"
                    ],
                    "guid": "s21kN<KD@R",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "\\(\\int a^{x} d x\\)",
                        "\\(\\frac{a^{x}}{\\ln a}+c\\)"
                    ],
                    "guid": "w9wPHiN[MG",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "\\(\\int \\frac{1}{x} dx\\)",
                        "\\(\\ln |x|+c\\)"
                    ],
                    "guid": "LVdjbPp0#r",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are grad, div, and curl?",
                        "<div>with continuously differentiable f'n f \\( f: R^{n} \\rightarrow R \\),</div>\\( \\text{grad}(f) = \\nabla f \\) is an n-dimensional operator: \\((\\nabla f)_i = \\frac{\\partial}{\\partial x_{i} } \\)<br><div><br></div><div>with continuously differentiable vector field \\( F:R^n \\rightarrow R^n \\),</div><div>\\( \\text{div}(F) = \\nabla \\cdot F = \\sum_{i} \\frac{\\partial F_{i}}{\\partial x_{i}}\\)</div><div><br></div><div>For cont. diff. \\(F : R^3 \\rightarrow R^3\\),&nbsp;</div><div>\\( \\text{curl}(F) = \\nabla \\times F = (\\ldots) \\)</div>"
                    ],
                    "guid": "PsSEt?ab=C",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are critical points of a multivariate function?",
                        "Critical points are values in the domain of a funciton where the gradient is either undefined or zero."
                    ],
                    "guid": "w?KzUAGZa1",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Chain rule: what's the derivative of \\(y = f(g(h(x)))\\)?",
                        "\\(y' = f'(g(h(x))) \\cdot g'(h(x)) \\cdot h'(x) \\)"
                    ],
                    "guid": "H(ZF3J=$Pm",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "4277739c-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "42777644-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "220px-Sorting_stability_playing_cards.svg.png",
                "74517A88-3B13-074B-BC35-F2C5962A8A12.png",
                "Dynamic-Programming-1-1024x512.png",
                "Merge-Sort-Tutorial.png",
                "QuickSort2.png",
                "jit.png",
                "pass-by-reference-vs-pass-by-value-animation.gif"
            ],
            "name": "computer_science",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What is multithreading?",
                        "<div>Ability of a central processing unit (CPU) to execute multiple processes or threads concurrently.</div><div><br></div><div>The software we run on our computers is a <b>process</b></div><div><b><br></b></div><div>A process is a unit of work you are assigning the CPU</div><div><br></div><div>A thread is a lightweight process</div><div><br></div><div>A process contains one or multiple threads</div><div><br></div><div><br></div><div>Example</div><div><br></div><div>When you enter a character on microsoft word there are threads that are&nbsp;</div><div>Handling the display</div><div>Running grammar checking</div><div>Periodically saving the file</div><div><br></div><div><u>Pros</u>&nbsp;</div><div><b>lightweight</b>,&nbsp;</div><div>Take <b>advantage</b> of <b>unused computing resources</b></div><div><b>share</b> the s<b>ame memory as parent process</b></div><div>Independent sequences of execution</div><div><br></div>"
                    ],
                    "guid": "kySlTg>AoO",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is an array?",
                        "An array is a series of memory locations, it stores values of the same datatype."
                    ],
                    "guid": "1NGv(8@g$",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a hash table?",
                        "<div>Hash function converts object into a bucket index</div><div><br></div><div>You store the object in the bucket with the correct index</div><div><br></div><div><img src=\"74517A88-3B13-074B-BC35-F2C5962A8A12.png\"><br></div>"
                    ],
                    "guid": "GP1io&obC.",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Pass by reference vs pass by value",
                        "<div>Python is pass by reference</div><div><br></div><div>When you pass an object you are passing a reference to the object</div><div><br></div><div>If you make a change to the object within the function that change is reflected in the object outside the function</div><div><br></div><div>Pass by value, a change of the object in the function is not reflected outside the function.</div><div><br></div><div><br></div><img src=\"pass-by-reference-vs-pass-by-value-animation.gif\">"
                    ],
                    "guid": "s9Yj[Y*mOY",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a random seed used for?",
                        "A random seed is a number/vector used to initialize a pseudorandom number generator<div><br></div><div>A pseudorandom number generator's number sequence is completely determined by the seed: thus, if a pseudorandom number generator is reinitialized with the same seed, it will produce the same sequence of numbers.</div>"
                    ],
                    "guid": "O_-K?DSn3p",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is NP Complete?",
                        "<strong>NP</strong>&nbsp;stands for&nbsp;<strong><em>Non-deterministic</em>&nbsp;Polynomial</strong>&nbsp;time<div><br></div><div><div>A problem x that is in NP is also in NP-Complete&nbsp;<em>if and only if</em>&nbsp;every other problem in NP can be quickly (ie. in polynomial time) transformed into x.</div><div><br></div><div><u>In other words:</u></div><b>x is in NP, and every problem in NP is&nbsp;<em>reducible</em>&nbsp;to x</b></div><div><br></div><div><div>So, what makes&nbsp;<em>NP-Complete</em>&nbsp;so interesting is that <b>if any one of the NP-Complete problems was to be solved quickly, then all&nbsp;<em>NP</em>&nbsp;problems can be solved quickly.</b></div></div><div><div><br></div><div>&nbsp;<br></div></div>"
                    ],
                    "guid": "J4JH[dk},.",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is JIT compilation?",
                        "Just in time compilation&nbsp;<div><br></div><div>Interpreting the bytecode which is the standard implementation of the Java Virtual Machine (JVM) makes execution of programs slow.</div><div><b>The JIT compiler helps improve the performance of Java programs by compiling bytecode into native machine code at run time.&nbsp;</b></div><div><br></div><div>When using a JIT compiler, the hardware can execute the native code, as opposed to having the JVM interpret the same sequence of bytecode repeatedly and incurring the penalty of a relatively lengthy.<br><br></div><div><img src=\"jit.png\"><br></div>"
                    ],
                    "guid": "K$2*p4`2fE",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is continuous integration (CI) ?",
                        "Process of automating the build and testing of code every time a team member commits changes to version control.<div>(Think of Drone from Cogent)<br></div>"
                    ],
                    "guid": "sJ2aM|@0*K",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is stack overflow?",
                        "<b>Stack overflow occurs if the call stack pointer exceeds the stack bound.</b><div><b><br></b><div>The call stack may consist of a limited amount of&nbsp;address space, often determined at the start of the program.<br></div><div><br></div><div>The most common cause of stack overflow is excessively deep or infinite recursion, in which a function calls itself so many times that the space needed to store the variables and information associated with each call is more than can fit on the stack.</div><div><br></div><div>When a program attempts to use more space than is available on the call stack (that is, when it attempts to access memory beyond the call stack's bounds, which is essentially a&nbsp;buffer overflow), the stack is said to&nbsp;<i>overflow</i>, typically resulting in a program crash.<br></div></div>"
                    ],
                    "guid": "l]dzPX4pf9",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is Dynamic Programming?",
                        "Programming paradigm that solves a given complex problem by breaking it into subproblems and stores the results of subproblems to avoid computing the same results again.<div><br></div><div><div><u><br>Main Properties</u></div><div>1.&nbsp;<b>Overlapping subproblems</b></div><div>&nbsp; &nbsp; Subproblems recur many times&nbsp;</div><div>&nbsp; &nbsp; Solutions can be cached and reused</div><div><br></div><div>2.&nbsp;<b>Optimal substructure</b></div><div>&nbsp; &nbsp; Optimal solution can be decomposed into subproblems</div><div><br></div><div><img src=\"Dynamic-Programming-1-1024x512.png\"><br></div><div><br></div></div>"
                    ],
                    "guid": "jV-@.kGb*M",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe quicksort&nbsp;",
                        "The array of elements is divided into parts repeatedly until it is not possible to divide it further.<div><br><div>It is also known as&nbsp;<strong>“partition exchange sort”</strong>.</div><div><br></div><div>It uses a key element (pivot) for partitioning the elements.</div><div><br></div><div>One left partition contains all those elements that are smaller than the pivot and one right partition contains all those elements which are greater than the key element.</div></div><div><br></div><div><img src=\"QuickSort2.png\"><br></div>"
                    ],
                    "guid": "m}T3*5MPC:",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe Mergesort",
                        "The elements are split into two sub-arrays (n/2) again and again until only one element is left.<div><br><div>Merge sort uses additional storage for sorting the auxiliary array.</div><div><br></div><div>Merge sort uses three arrays where two are used for storing each half, and the third external one is used to store the final sorted list by merging other two and each array is then sorted recursively.</div><div><br></div><div>At last, the all sub arrays are merged to make it ‘n’ element size of the array.</div></div><div><br></div><div><img src=\"Merge-Sort-Tutorial.png\"><br></div>"
                    ],
                    "guid": "kq._xJ.v?j",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How are floating point numbers represented?",
                        "<u>IEEE format</u><div><b>Sign bit</b></div><div><b><br></b></div><div><b>Biased exponent (8 bits)</b></div><div><b><br></b></div><div><b>Fraction (23 bits)</b></div><div><br></div><div><u>Scientific Notation</u></div><div>1.637 x 10 ^ 4</div><div><br></div><div>Mantissa is 1.637</div><div>Base is 10</div><div>Exponent is 4</div>"
                    ],
                    "guid": "A.qXO9a#Y9",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What does it mean for a sorting algorithm to be stable?",
                        "A sorting algorithm is said to be stable if objects with equal values maintain their relative positions<div><br></div><div><img src=\"220px-Sorting_stability_playing_cards.svg.png\"><br></div>"
                    ],
                    "guid": "ODxbj7e6q|",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the incremental mean",
                        "The mean \\(\\mu_{1}, \\mu_{2}, \\ldots\\) of a sequence \\(x_{1}, x_{2}, \\ldots\\) can be computed<br>incrementally,<div><br></div><div>\\(\\begin{aligned} \\mu_{k} &amp;=\\frac{1}{k} \\sum_{j=1}^{k} x_{j} \\\\ &amp;=\\frac{1}{k}\\left(x_{k}+\\sum_{j=1}^{k-1} x_{j}\\right) \\end{aligned}\\)</div><div><br></div><div>\\(\\mu_{k} = \\mu_{k-1}+\\frac{1}{k}\\left(x_{k}-\\mu_{k-1}\\right)\\)<br></div><div><br></div><div>\\(\\left(x_{k}-\\mu_{k-1}\\right)\\) can be seen as the error between the new value \\(x_{k}\\) and \\(\\mu_{k-1}\\).&nbsp;</div><div>We update the mean by moving it a bit closer to&nbsp;&nbsp;\\(x_{k}\\) .<br></div>"
                    ],
                    "guid": "FyE1hz}|%i",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why is it hard to perform continuous math on a computer?",
                        "<div>we need to represent inﬁnitely many real numbers with a ﬁnite number of bit patterns.</div><div><br></div><div><div>we incur some approximation error when we represent the number in the computer.</div></div>"
                    ],
                    "guid": "LC;>vrFYzW",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is numerical underflow?",
                        "When numbers near zero are rounded to zero"
                    ],
                    "guid": "mz|{lJ2RL;",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is numerical overflow?",
                        "Numbers with large magnitude are represented as&nbsp;\\(\\infty\\) or \\(-\\infty\\)"
                    ],
                    "guid": "J>+b}m+-qh",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe log and sqrt numerical precision errors?",
                        "log(0) = - inf<div><br></div><div>log(&lt;negative&gt;) is imaginary, usually nan in software<br></div><div><br></div><div>sqrt(0) is 0, but its derivative has a divide by zero<br></div>"
                    ],
                    "guid": "CVK-EAcLdt",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are some common causes of Nans, Large values?",
                        "log<div><br></div><div>exp</div><div><br></div><div>sqrt</div><div><br></div><div>division</div>"
                    ],
                    "guid": "E2oRuXVs@N",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are underflow and overflow?",
                        "Under/overflow occur when the result of a computation is too small/large to be represented by the target data type."
                    ],
                    "guid": "yZazwZHc5Z",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How to detect a cycle in a sequence?",
                        "Floyd's algorithm (tortoise and hare).<div>Three steps:<br><div>1. Is there a cycle? <br>&nbsp; &nbsp; &nbsp;Traverse list, each step incrementing pointer <b>p1</b> by 1 and <b>p2</b> by 2. Cycle found when *<b>p1</b>==*<b>p2</b></div><div><b><br></b></div><div>2.<b>&nbsp;</b>Where does the cycle start?</div><div>&nbsp; &nbsp; Reset <b>p1</b> to sequence start, then increment both pointers by 1 until they are equal. Number of steps = first repetition of cycle.</div><div><br></div><div>3. What is the length of the shortest cycle?</div><div>&nbsp; &nbsp;With both pointers initially at the start of the cycle, increment one and leave the other still, stopping when *<b>p1</b>==*<b>p2</b>. Number of steps = length of shortest cycle.&nbsp;<br><div><br></div></div></div>"
                    ],
                    "guid": "HT!FivAFh*",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "4277c89c-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "4277cc48-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "320px-Logistic-curve.svg.png",
                "Screenshot 2019-06-08 at 21.20.36.png",
                "paste-06cd1a587ea72e95bb27daf62e9d6aab34d0f127.jpg",
                "paste-28e92ceec30591047642344e00c765040e6e88eb.jpg",
                "paste-74391660b588d94f75bf534f7d283e2253b3abe9.jpg",
                "paste-7d9ad0adde3e7377fb21954a511fa858007a36ee.jpg",
                "paste-e554bc639c8c601fa51d06abfce3a04e1cf89104.jpg",
                "paste-e73d02834be20f6f5e0d49c43ea2facd4bd194e6.jpg",
                "paste-e76dd00f485f85210c449e99af684da7fb106f01.jpg"
            ],
            "name": "deep_learning",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the sigmoid function?",
                        "<div>\\(S(x)=\\frac{1}{1+e^{-x}}\\)<br></div><img src=\"320px-Logistic-curve.svg.png\"><div><br></div><div><br></div><div><div>sigmoid function <b>saturates</b> when its <b>argument is very positive or very negative</b>,</div><div>meaning that the<b> function becomes very ﬂat and insensitive to small changes in its</b></div><div><b>input.</b></div></div>"
                    ],
                    "guid": "G>+9IG&o2<",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How does the softmax function suffer from overflow and underflow?",
                        "\\(\\operatorname{softmax}(\\boldsymbol{x})_{i}=\\frac{\\exp \\left(x_{i}\\right)}{\\sum_{j=1}^{n} \\exp \\left(x_{j}\\right)}\\)<div><br></div><div>If a constant c is very negative then&nbsp;\\(\\exp (c)\\) will underflow. Making the denominator of the softmax will become 0 and the final result will be undefined.</div><div><br></div><div>If a constant c is very positive then&nbsp;\\(\\exp (c)\\) will overflow, resulting in an undefined expression.</div><div><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "riw?N<V~od",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe label smoothing?",
                        "<div><div><b>Prevents the pursuit of hard probabilities without discouraging correct classiﬁcation.</b></div></div><div><br></div>Regularizes a model based on a softmax with k output values,&nbsp;by replacing the hard 0 and 1 classiﬁcation targets with soft targets of epsilon/k-1 and 1 - epsilon.&nbsp;<div>ML learning may actually never converge i.e. the softmax can never predict exactly 0 or exactly 1, so it will continue to learn larger weights, making more extreme predictions.</div><div><br></div><div><br></div><div><br></div><div><br><div><br></div></div>"
                    ],
                    "guid": "oIn<(N$<U9",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe parameter sharing?",
                        "Force sets of parameters to be equal.<div><br></div><div><div>only a subset of the parameters (the unique set) needs to be stored in memory.</div></div>"
                    ],
                    "guid": "m[`p=i{3@D",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Given an example of why dropout works?",
                        "<div>If the model learns a hidden unit h_i that detects a face by ﬁnding the nose, then dropping h_i corresponds to erasing the information that there is a nose</div><div>in the image. The model must learn another h_i, that either redundantly encodes the presence of a nose or detects the face by another feature, such as the mouth.</div>"
                    ],
                    "guid": "ttl_j>QCh=",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is an adversarial example?",
                        "An intentionally constructed example that is constructed by using an optimization procedure to search for an input&nbsp;\\(\\boldsymbol{x}^{\\prime}\\) near a data point&nbsp;\\(\\boldsymbol{x}\\) such that the model output is very different at&nbsp;\\(\\boldsymbol{x}^{\\prime}\\) .&nbsp;<div><br></div><div><img src=\"paste-e73d02834be20f6f5e0d49c43ea2facd4bd194e6.jpg\"><br></div><div><br></div><div><div>In many cases&nbsp;\\(\\boldsymbol{x}^{\\prime}\\)&nbsp; can be so similar to \\(\\boldsymbol{x}\\) that a human can not tellt the difference.</div></div>"
                    ],
                    "guid": "FhTa2g0f0N",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In backpropagation, what does the add gate do?",
                        "The add gate takes gradient on its output and distributes it equally to all of its inputs"
                    ],
                    "guid": "Q&om6Mx2XQ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe curriculum learning?",
                        "Planning a learning process to begin by learning simple concepts and progress to learning more complex concepts that depend on these similar concepts<div><br></div><div>Motivation comes from the observation that humans and animals seem to learn better when trained with a curriculum like a strategy.<br></div>"
                    ],
                    "guid": "HK]C;K;i(y",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the key concept of AdaGrad",
                        "Adapts the LR of all model parameters by scaling them inversely proportional to the square root of the sum of all historical squared values of the gradient<div><br></div><div><i>Allows for greater progress in more gently sloped directions of hyperparameter space</i></div>"
                    ],
                    "guid": "ihd=Nffw/c",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the difference between AdaGrad and RMSProp",
                        "RMSProp changes the sum of all historical squared values of the gradients into an exponentially weighted moving average.&nbsp;<div><br></div><div>This discards the history from extreme past.</div>"
                    ],
                    "guid": "k;hc`[<t#e",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What does batch normalization do?",
                        "To <b>increase the stability of a neural network</b>, batch normalization normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.<div><br></div><div>\"Reduces the amount that input to a hidden layer shifts around - <b>ensures mean and variance of input distribution/values stays the same</b>\"<br><div><br></div><div>\"Gradient will never propose an operation that acts simply to increase std or mean of h_i\"</div><div><br></div><div>Z =XW<br></div><div><br></div><div>\\(\\tilde{Z}=Z-\\frac{1}{m} \\sum_{i=1}^{m} Z_{i, :}\\)<br></div><div><br></div><div>\\(\\hat{Z}=\\frac{\\tilde{Z}}{\\sqrt{\\epsilon+\\frac{1}{m} \\sum_{i=1}^{m} \\tilde{Z}_{i,}^{2}}}\\)<br></div><div><br></div><div>\\(\\boldsymbol{H}=\\max \\{0, \\boldsymbol{\\gamma} \\hat{Z}+\\boldsymbol{\\beta}\\}\\)<br></div><div><br></div><div><img src=\"paste-28e92ceec30591047642344e00c765040e6e88eb.jpg\"><br></div><div><br></div></div>"
                    ],
                    "guid": "FmjMWl[W!f",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the parameter sharing property of CNNs",
                        "<div>Parameter sharing refers to using the same parameter for more than one function in a model.</div><div><br></div><div>In a traditional NN each element of the weight matrix is used exactly once when computing the output of a layer and never used again.</div><div><br></div><div><div><b>In a convolutional neural net, each member of the kernel is used at every position of the input.&nbsp;</b></div></div><div><div><b>We only learn one set of parameters for every position of the input.</b></div></div>"
                    ],
                    "guid": "rTnN>Jc:1W",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are the stages in a CNN?",
                        "1. Layer performs several convolutions<div>2. Each linear activation is passed through a non linear activation function (Detector stage)</div><div>3. Use a pooling function to modify the output of the layer further</div>"
                    ],
                    "guid": "suE.AWXRdZ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "<div>Why can a convolutional net be described as being similar to a fully connected net, but with an inﬁnitely strong prior over its weights?</div>",
                        "<div>This inﬁnitely strong prior says that the weights for one hidden unit must be identical to the weights of its neighbor but shifted in space.</div><div><div><br></div><div>The prior also says that the weights must be zero, except for in the small, spatially contiguous receptive ﬁeld assigned to that hidden unit.</div></div><div><br></div><div>Leading to translation equivariance and invariance to small translations</div><div><br></div>"
                    ],
                    "guid": "u<p-V%E!|G",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Draw the structure of a folded an unfolded RNN",
                        "<div><div>A recurrent network with no outputs. This recurrent network just processes information from the input x by incorporating it into the state h that is passed forward through time.</div></div><img src=\"paste-e554bc639c8c601fa51d06abfce3a04e1cf89104.jpg\">"
                    ],
                    "guid": "wf^b{!4cGO",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe bidirectional RNNs",
                        "Used when we want to output a predcition that may depend on the whole input sequence.&nbsp;<div>This allows the output units \\(\\boldsymbol{o}^{(t)}\\) to compute a representation that depends on both the past and the future but is most sensitive to input values around time t.</div><div><br></div><div>\\(\\boldsymbol{h}^{(t)}\\) standing for the state of the sub-RNN that moves forward through time and \\(\\boldsymbol{g}^{(t)}\\) standing for the state of the<br></div>sub-RNN that moves backward through time.&nbsp;<div><br></div><div><img src=\"paste-74391660b588d94f75bf534f7d283e2253b3abe9.jpg\"><br></div>"
                    ],
                    "guid": "i_DxME<.+",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe&nbsp;Encoder-Decoder Sequence-to-Sequence architecture",
                        "<div>1.) An encoder or reader or input RNN processes the input sequence</div><div><br></div><div>The encoder emits the vector, context C<br></div><div><br></div><div>2.)&nbsp;A decoder or writer or output RNN is conditioned on that ﬁxed-length vector C to generate the output sequence&nbsp; \\(\\boldsymbol{Y}=\\left(\\boldsymbol{y}^{(1)}, \\ldots, \\boldsymbol{y}^{\\left(n_{y}\\right)}\\right)\\).&nbsp;</div><div><br></div><div>in earlier architectures the lengths \\(n_{x}\\) and \\(n_{y}\\) can vary from each other, while previous architectures constrained \\(n_{x}=n_{y}=\\tau .\\)&nbsp;<br></div><div><br></div><div><div>One clear limitation of this architecture is when the context C output by the encoder RNN has a dimension that is too small to properly summarize a long sequence.&nbsp;</div></div><div><br></div><div><img src=\"Screenshot 2019-06-08 at 21.20.36.png\"><br></div>"
                    ],
                    "guid": "q906l%Ve)I",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe denoising autoencoders",
                        "DAEs (Denoising Autoencoders) learn to map a corrupted copy of \\(\\tilde{x}\\) of \\(x\\) back to \\(x\\).<div><br><div>1. Have \\(x\\). Corrupt with \\(C(\\tilde{x} \\vert x)\\) to get \\(\\tilde{x}\\).<br></div><div>2. Train autoencoder functions f_{\\theta}, g_{\\phi} to minimize&nbsp; loss \\(L(x, g(f(\\tilde{x})))\\)</div><div><div><br></div><div><br></div><div>Training forces \\(f_{\\theta}\\) and \\(g_{\\phi}\\) to implicitly learn the structure of \\(p_{\\text { data }}(\\boldsymbol{x})\\).<br></div><div><div>The autoencoder learns a vector ﬁeld (green arrows below) that maps corrupted values back to the data manifold.&nbsp;</div></div></div><div><img src=\"paste-7d9ad0adde3e7377fb21954a511fa858007a36ee.jpg\"></div></div>"
                    ],
                    "guid": "s(PG~0#_wX",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do autoencoders learn the structure of a manifold?",
                        "<div>The autoencoder can aﬀord to <b>represent only the variations that are needed to reconstruct training examples</b>.</div><div><br></div><div><div><b>If</b> the <b>data-generating distribution concentrates near a low-dimensional manifold</b>, this <b>yields representations that implicitly capture a local coordinate system for this manifold</b></div></div><div><br></div><div><div>only the variations tangent to the manifold around <b>x</b>&nbsp;need to correspond to changes in h = f(x)&nbsp;</div><div>(as defined by the tangent planes) (the autoencoder need not successfully reconstruct inputs that are not probable under the data-generating distribution)</div><div><br></div></div><div><div>Hence the <b>encoder learns a mapping from the input space x to a representation space</b>.&nbsp;</div><div>A <b>mapping</b> that is <b>only</b> <b>sensitive to changes along the manifold directions</b>, but that is <b>insensitive to changes orthogonal to the manifold</b></div></div><div><b><br></b></div><div><div>By making the reconstruction function insensitive to perturbations of the input around the data points, we cause the autoencoder to recover the manifold structure</div></div>"
                    ],
                    "guid": "M>Q5D#B2{v",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What makes for a good representation?",
                        "A good representation is one that makes the subsequent learning task easier."
                    ],
                    "guid": "s+`.&WhTc(",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe semi-supervised learning",
                        "Learn good representations for the unlabeled data (usually have a lot of data for), and then use these representations to solve the supervised learning task (usually with a little data)."
                    ],
                    "guid": "KrVF,p**5J",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How does pretraining a network change learning trajectory?",
                        "<div><div><b>Training consistently terminates in one region when using pretraining.</b></div></div><div><div><br></div><div>The small region corresponding to pretrained models may indicate that the pretraining-based estimator has reduced variance.</div></div><div><br></div><img src=\"paste-06cd1a587ea72e95bb27daf62e9d6aab34d0f127.jpg\"><br>"
                    ],
                    "guid": "qei.j2:1k:",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Briefly describe transfer learning",
                        "<div>The learner must perform two or more diﬀerent tasks, but we assume that many of the factors that explain the variations in P1 are relevant to the variations that need to be captured for learning&nbsp; P2.</div>"
                    ],
                    "guid": "y/A@{VbY!B",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Breifly describe domain adaption",
                        "<b>The task (and the optimal input-to-output mapping) remains the same between each setting, but the input distribution is slightly different.</b><div><br></div><div><div>For example, consider the task of sentiment analysis, which consists of determining whether a comment expresses positive or negative sentiment</div></div><div><br></div><div><div>A domain adaptation scenario can arise when a sentiment predictor trained on customer reviews of media content, such as books, videos and music, is later used to analyze comments about consumer electronics.</div></div><div><br></div><div><div>There might an underlying function that tells whether any statement is positive, neutral, or negative, but of course the vocabulary and style may vary from one domain to another, making it more diﬃcult to generalize across domains.</div></div><div><br></div><div>Unsupervised pre-training with DAEs has been found to be very successful for sentiment anlysis with domain adaption.</div>"
                    ],
                    "guid": "H*epp5$r9?",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Briefly describe one-shot learning",
                        "<div><b>Only one labeled example of the transfer task is given for one-shot learning.</b></div><div><br></div><div><div>This is possible because the representation learns to cleanly separate the underlying classes during the ﬁrst stage. During the transfer learning stage, only one labeled example is needed to infer the label of many possible test examples that all cluster around the same point in representation space.</div></div>"
                    ],
                    "guid": "MS$_O@$U+o",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe zero-shot learning in relation to transfer learning.",
                        "<div><div>Transfer learning: ML system uses training on task P1 to more efficiently learn task P2. E.g. pre-training, few-shot, etc</div><div>Zero shot learning: ML system gains the ability to complete a task without learning directly on any examples of that task.&nbsp;</div><div><br></div><div>For example: Encoders \\(f_{x}\\) and \\(f_{y}\\) map values \\(x\\) and \\(y\\) in their respective domains to representations \\(h_{x}\\) and \\(h_{y}\\).&nbsp;</div><div><br></div><div>With a (learned) map between the representation spaces, the label \\(y\\) can be associated with vector \\(x\\), even if the system never saw class-specific training pairs \\( (x, y) \\).</div><br></div><img src=\"paste-e76dd00f485f85210c449e99af684da7fb106f01.jpg\">"
                    ],
                    "guid": "ie(!z~5PP@",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is Distributed Representation?",
                        "<div><b>Representations composed of many elements that can be set separately from each other</b> are one of the most important tools for representation learning.</div><div><br></div><div><div>Distributed representations are powerful because they can use \\(n\\) features with \\(k\\) values to describe \\(k^n\\) distinct concepts</div></div>"
                    ],
                    "guid": "wW6Z(%;jN^",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How can we avoid under/overflow with softmax?",
                        "<div>softmax \\( A_{i} = \\text{log}\\left( \\frac{\\exp(z_{i})}{\\sum_{j=1}^{n} \\exp(z_{j})} \\right) \\)</div><div>\\( = z_{i} - \\text{log}\\left( \\sum_{j=1}^{n} \\exp(z_{j}) \\right) \\)<br></div><div>\\( = z_i - Z - \\text{log}\\left( \\sum_{j=1}^{n} \\exp(z_{j}) - Z \\right) \\).</div><div>Choose the right \\(Z = \\max_j z_j\\).</div>"
                    ],
                    "guid": "Cb$[5]/b</",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the logistic function?",
                        "\\[ S(x) = \\frac{1}{1 + \\exp(-x)} = \\frac{\\exp(x)}{1+\\exp(x)} \\]"
                    ],
                    "guid": "iE~wP>~Im7",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the softplus function?",
                        "\\[ f(x) = \\ln(1+\\exp(x) )\\]"
                    ],
                    "guid": "C!JvfvTH3Y",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is Attention?",
                        "<div>Scaled dot-product attention:</div>\\[\\text{Attention}(Q,K,V) = \\text{softmax}\\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) V \\]"
                    ],
                    "guid": "hJ,YGY8L>J",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "427844e8-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "4278497a-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [],
            "name": "discrete_math",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "How do you find the number of different permutations of n objects, of which \\(n_{1}\\) are alike, \\(n_{2}\\) are alike, and \\(n_{r}\\) are alike?",
                        "\\(\\left( \\begin{array}{c}{n} \\\\ {n_{1}, n_{2}, \\ldots, n_{r}}\\end{array}\\right)=\\frac{n !}{n_{1} ! n_{2} ! \\cdots n_{r} !}\\)"
                    ],
                    "guid": "Py|BT0uYw%",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the formula for combinations?",
                        "<div>The number of different groups of \\(r\\) items that could be formed from a set of \\(n\\) items is, when order is not relevant<br></div><div><br></div>\\(\\left( \\begin{array}{l}{n} \\\\ {r}\\end{array}\\right)=\\frac{n !}{r !(n-r) !}\\)<div><br></div><div>Order not relevant means ABC = {BAC, CBA, CAB, BCA,&nbsp; .. }</div>"
                    ],
                    "guid": "t5q?97[KWj",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the binomial theorem?",
                        "\\((x+y)^{n}=\\sum_{i=0}^{n} \\left( \\begin{array}{c}{n} \\\\ {i}\\end{array}\\right) x^{i} y^{n-i}\\)"
                    ],
                    "guid": "gJQ.j$O%dG",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "427866d0-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "42786a36-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "paste-e046daad9e4675ad1bcea87cd0197063aff7d340.png"
            ],
            "name": "general_math",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What does it mean to be equivariant?",
                        "<div>equivariant means that <b>if the input changes, the output changes in the same way.</b></div><div><div><br></div><div>Speciﬁcally, a function f(x) is equivariant to a function g if f(g(x)) = g(f(x))</div></div>"
                    ],
                    "guid": "N50c{TW6^8",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the set of tangent planes of a manifold?",
                        "<div>At a point x on a d-dimensional manifold, the <b>tangent plane is given by</b> <b>d basis vectors</b> that <b>span</b> the <b>local directions of variation</b> <b>allowed on the manifold.</b></div><div><b><br></b></div><div><div>These local directions specify how one can change x inﬁnitesimally while staying on the manifold</div></div><div><br></div><div><img src=\"paste-e046daad9e4675ad1bcea87cd0197063aff7d340.png\"><br></div><div>An n-dimensional manifold has an n-dimensional tangent plane at every point.</div><div>It <b>deﬁnes the space of directions in which it is possible to move while remaining on the manifold</b>.</div><div>We indicate an example tangent line at one point in the image above.</div><div><br></div><div><div><b>Gray pixels indicate pixels that do not change as we move along the tangent line, white pixels indicate pixels that brighten, and black pixels indicate pixels that darken</b></div></div><div><br></div><div><br></div>"
                    ],
                    "guid": "jt8kQw#<|#",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "427885fc-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "427888c2-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "Screenshot 2019-05-18 at 10.31.21.png",
                "paste-553e6de55f0302f2e8a1a1b135e0c4c077f8b405.jpg"
            ],
            "name": "information_theory",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the basic intuition behind information theory?",
                        "<div><b>Learning that an unlikely event has occurred is more informative than learning that a likely event has occurred.</b></div><div><br></div><div><div>Likely events should have low information content, and in the extreme case,</div><div>events that are guaranteed to happen should have no information content</div><div>whatsoever</div></div><div><br></div><div>Less likely events should have higher information content.<br></div><div><br></div><div><div>Independent events should have additive information. For example, ﬁnding</div><div>out that a tossed coin has come up as heads twice should convey twice as</div><div>much information as ﬁnding out that a tossed coin has come up as heads</div><div>once.</div></div>"
                    ],
                    "guid": "HO&00G:CU@",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Define self-information",
                        "The self-information of event&nbsp;\\(\\mathrm{x}=x\\) to be&nbsp;<div><br><div>\\(I(x)=-\\log P(x)\\)<br></div><div><br></div><div>the unit for this is <b>nats</b></div></div><div><b><br></b></div><div><b>Deals only with a single outcome</b></div>"
                    ],
                    "guid": "QL|0/,@-kE",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What does one nat mean?",
                        "One nat is the amount of information gained by observing an event of probability&nbsp;\\(\\frac{1}{e}\\)."
                    ],
                    "guid": "L3OwRz;j=c",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is Shannon Entropy?",
                        "<div>Shannon entropy of a distribution is the expected amount of information in an event drawn from that distribution.&nbsp;<br></div><div><br></div><div>\\(H(\\mathrm{x})=\\mathbb{E}_{\\mathrm{x} \\sim P}[I(x)]=-\\mathbb{E}_{\\mathrm{x} \\sim P}[\\log P(x)]\\)<br></div><div><br></div><div><div>It gives a lower bound on the number of bits (if the logarithm is base 2) needed on average to encode symbols drawn from a distribution P.</div></div><div><br></div><div><img src=\"Screenshot 2019-05-18 at 10.31.21.png\"><br></div>"
                    ],
                    "guid": "O{(oVBA*<z",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What type of distributions have low entropy?",
                        "<div>Distributions that are nearly deterministic (where the outcome is nearly certain) have low entropy;</div><div><br></div><div>Deterministic distribution examples include a two-headed coin and rolling a&nbsp;die&nbsp;whose sides all show the same number.<br></div>"
                    ],
                    "guid": "r>$uPzlL-w",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What type of distributions have high entropy?",
                        "Distributions that are closer to uniform have high entropy.<div><br></div><div><div>Shannon entropy of a binary random variable. The plot shows how distri-</div><div>butions that are closer to deterministic have low Shannon entropy while distributions</div><div>that are close to uniform have high Shannon entropy.&nbsp;</div><div><br></div><div>On the horizontal axis, we plot p, the probability of a binary random variable being equal to 1.&nbsp;</div><div><br></div><div>The entropy is given by (p −1)log(1− p) − p log p.&nbsp;</div><div><br></div><div>When p is near 0, the distribution is nearly deterministic, because the random variable is nearly always 0.&nbsp;</div><div>When p is near 1, the distribution is nearly deterministic, because the random variable is nearly always 1.&nbsp;</div><div>When p = 0.5, the entropy is maximal, because the distribution is uniform over the two outcomes.</div><div><br></div><div><img src=\"paste-553e6de55f0302f2e8a1a1b135e0c4c077f8b405.jpg\"><br></div><div><br></div><div><br></div></div>"
                    ],
                    "guid": "xW!!3=(^pR",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is KL Divergence?",
                        "<div>If we have two separate probability distributions P(x) and Q(x) over the same random variable x, it <b>measures how diﬀerent these two distributions are</b></div><div><br></div><div>\\(D_{\\mathrm{KL}}(P \\| Q)=\\mathbb{E}_{\\mathrm{x} \\sim P}\\left[\\log \\frac{P(x)}{Q(x)}\\right]=\\mathbb{E}_{\\mathrm{x} \\sim P}[\\log P(x)-\\log Q(x)]\\)<br></div><div><br></div><div><br></div><div>It is the extra amount of nats needed to send a message containing symbols draw from probability distribution P when we use a code that was designed to minimize</div><div>the length of messages drawn from probability distribution Q</div><div><br></div><div><br></div><div><b><u>Properties</u></b></div><div><b><u><br></u></b></div><div>Non negative</div><div><b><u><br></u></b></div><div>KL Divergence is 0 if and only if P and Q are the same distribution in discrete variables, or equal “almost everywhere” in the case of continuous</div><div>variables.</div><div><br></div><div><div>Not a true distance measure because it is not symmetric</div></div>"
                    ],
                    "guid": "M1-2(>kRXQ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is cross entropy?",
                        "\\(H(P, Q)=H(P)+D_{\\mathrm{KL}}(P \\| Q)\\)<div>\\(H(P, Q)=-\\mathbb{E}_{\\mathbf{x} \\sim P} \\log Q(x)\\)<br></div><div><br></div><div><div>Minimizing the cross-entropy with respect to Q is equivalent to minimizing the KL divergence, because Q does not participate in the omitted term.</div></div>"
                    ],
                    "guid": "KN]W&JMbi=",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Define self-information. What are the units?",
                        "Self-information (or surprisal) is a convenient way of expressing probability in the context of information theory.&nbsp;<div><br></div><div>Given an event \\(x\\) with probability \\(P\\), it is</div><div>\\[ I(x) \\mathrel{\\mathop:}= -\\log_{b} P \\],&nbsp;</div><div>If the base \\(b\\) is 2, then it is measured in units of bits.</div>"
                    ],
                    "guid": "m~>D6$eSjB",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the Kullback-Leibler (KL) divergence?",
                        "The KL divergence measures the difference between a probability distribution P and a reference probability distribution Q.<div><br><div>\\[ D_{\\text{KL}} (P \\Vert Q) = \\sum_{x \\in X} P(x) \\log \\left( \\frac{P(x)}{Q(x)} \\right) \\]<br></div></div>"
                    ],
                    "guid": "QZIID4]UQl",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is Shannon entropy? Differential entropy?",
                        "The Shannon entropy of a random variable is the average information / surprise / uncertainty across all possible outcomes.<div><br></div><div>Shannon entropy:</div><div>\\[ H(X) = - \\sum_{i=1}^{n} P(x_{i}) \\log_{b} P(x_{i}) \\]</div><div><br></div><div>Differential entropy:</div><div>\\[ h(X) = - \\int_{X} f(x) \\log_{b} f(x) dx \\]</div>"
                    ],
                    "guid": "sBb;Tfim.J",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Can KL divergence be used as a distance measure (metric)?",
                        "A metric \\(d\\) on a set \\(X\\) must satisfy<div><br><div>1. identity of indiscernables \\(d(x,x)=0\\),</div><div><br></div><div>2. symmetry \\( d(x,y) = d(y,x) \\),</div><div><br></div><div>3. subadditivity \\( d(x,y) \\leq d(x,z)+d(z,y) \\).</div><div><br></div><div>KL divergence satisfies 1 but not 2 or 3.</div></div>"
                    ],
                    "guid": "HN`=Ng&<f+",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is cross-entropy?",
                        "The cross entropy of a distribution \\(q\\) relative to a distribution \\(p\\).&nbsp;<div>More formally:<br><div>\\[ \\begin{align} H(p,q) &amp;= -E_{p} [ \\log q ] \\\\<br>&amp;= -\\sum_{x \\in X} p(x) \\log q(x) \\\\<br>&amp;= H(p) + D_{\\text{KL}}(p \\Vert q)&nbsp; \\end{align} \\]</div></div>"
                    ],
                    "guid": "BvoTDhZnTD",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "4278beb4-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "4278c15c-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "34D57D9B-73DA-954B-8FDD-E8D13AA51919.png",
                "B6B64759-8F5A-9942-A98F-FBE06805BDF7.png",
                "paste-8bfceaac2074b90ce8e0d0159e4b17db64de1227.jpg",
                "paste-ade2b2cb3d57b49c456c1f821d28d4b2ff48fe8b.jpg",
                "paste-cb71290fab5365eb270fb80d7b8deb7772a9f19f.jpg",
                "tensor-illustration.jpg"
            ],
            "name": "linear_algebra",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a positive definite matrix?",
                        "A positive definite matrix \\(M\\) is a symmetric matrix with \\(\\lambda_{i} &gt; 0\\) for all eigenvalues.<div><br></div><div>\\( z^{T} M^{k} z)&nbsp; &gt; 0\\) for all \\(z \\in \\mathcal{R} \\) for real-valued matrices<br><div><br><div>Meaning you can multiply the matrix by a vector multiple times without changing the sign of the vector.</div></div></div>"
                    ],
                    "guid": "E3C1nn{Lm!",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the Jacobian matrix?",
                        "<div>\\( J_{i,j} = \\frac{\\partial f_i }{\\partial x_{j}} \\)<br></div><div><br></div><div><div>= all partial derivatives of a function \\(f\\) whose input and output are both vectors</div></div><div><br></div><div><br></div>\\(<br>\\mathbf{J}=\\left[ \\begin{array}{ccc}{\\frac{\\partial \\mathbf{f}}{\\partial x_{1}}} &amp; {\\cdots} &amp; {\\frac{\\partial \\mathbf{f}}{\\partial x_{n}}}\\end{array}\\right]=\\left[ \\begin{array}{ccc}{\\frac{\\partial f_{1}}{\\partial x_{1}}} &amp; {\\cdots} &amp; {\\frac{\\partial f_{1}}{\\partial x_{n}}} \\\\ {\\vdots} &amp; {\\ddots} &amp; {\\vdots} \\\\ {\\frac{\\partial f_{m}}{\\partial x_{1}}} &amp; {\\cdots} &amp; {\\frac{\\partial f_{m}}{\\partial x_{n}}}\\end{array}\\right]<br>\\)<div><br></div>"
                    ],
                    "guid": "F.`tfyqSdy",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a Toeplitz matrix?",
                        "<div>A matrix where each descencding diagonal from left to right is constant</div><div><br></div>\\(\\left[ \\begin{array}{lllll}{a} &amp; {b} &amp; {c} &amp; {d} &amp; {e} \\\\ {f} &amp; {a} &amp; {b} &amp; {c} &amp; {d} \\\\ {g} &amp; {f} &amp; {a} &amp; {b} &amp; {c} \\\\ {h} &amp; {g} &amp; {f} &amp; {a} &amp; {b} \\\\ {i} &amp; {h} &amp; {g} &amp; {f} &amp; {a}\\end{array}\\right]\\)<div><br></div><div>One can represent linear convolution as a multiplication by a Toeplitz Matrix - instead of sliding a kernel across an image.</div>"
                    ],
                    "guid": "JPa-!N:cl,",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Norms vs Metrics (5 differences)",
                        "1. All norms are metrics.<div><br></div><div>2. Norms have a lot more structure than metric spaces</div><div><br></div><div>3. Due to generality metrics can be useless</div><div><br></div><div>4. A norm gives us the length of a vector&nbsp;measured from the origin, rather than a distance between points</div><div><br></div><div>5. Norm has a better geometric interpretation of condition 3 (Triangle in equality)&nbsp;<br><div><br></div></div>"
                    ],
                    "guid": "q0SaJDV_hg",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is linear independence?",
                        "<div> <div> <div>If none of the vectors in a set can be written as&nbsp; a linear combination of the others then the vectors are linearly independent.</div><div><br></div><div>The span of two linearly independent vectors will cover the full vector space</div><div><br></div><div><img src=\"34D57D9B-73DA-954B-8FDD-E8D13AA51919.png\"></div> </div></div>"
                    ],
                    "guid": "L4?<kay;<#",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the L1 norm?",
                        "The manhattan distance from the origin of the vector space.<div><br><div>\\(\\mathbf{x}=\\left[ \\begin{array}{c}{x_{1}} \\\\ {x_{2}} \\\\ {\\vdots} \\\\ {x_{n}}\\end{array}\\right]\\)<br></div><div><br></div><div>\\(|\\mathbf{x}|_{1}=\\sum_{r=1}^{n}\\left|x_{r}\\right|\\)<br></div><div><br></div><div><u><b>Properties</b></u></div><div><u>In terms of a loss function:</u></div><div>robust to outliers<br></div><div>produces sparse coefficients</div><div>Does not have analytical solution</div></div><div><br></div>"
                    ],
                    "guid": "vQ2bis#3V[",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the L2 norm?",
                        "Euclidean distance from the origin.<div><br></div><div>\\(|\\mathbf{x}|=\\sqrt{\\sum_{k=1}^{n}\\left|x_{k}\\right|^{2}}\\)<br></div><div><br></div><div><br></div><div><br></div><div><u><b>Properties</b></u></div><div><u>In terms of a loss function:</u></div><div>Stable - for any small adjustment in the datum the regression line will only move slightly</div><div>Has analytic solution</div><div><br></div><div><div>the squared L2 norm may be undesirable because it increases very slowly near the origin.</div></div>"
                    ],
                    "guid": "pA_NFpc!y#",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a tensor",
                        "An array of numbers arranged on a regular grid witha variable number of axes<div><br><div><br></div><div><img src=\"tensor-illustration.jpg\"><br><div><br></div><div>1D: Vector</div><div>2D: Arrray</div><div>3D: Cube</div><div>4D: Vector of Cubes</div></div></div>"
                    ],
                    "guid": "J*R0(eMb>k",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the matrix dot product?",
                        "<div>Also known as matrix product.</div><div>\\( C = AB \\)</div><div>\\( C_{i,j} = \\sum_{k} A_{i, k} B_{k, j} \\)<img src=\"paste-cb71290fab5365eb270fb80d7b8deb7772a9f19f.jpg\"></div>"
                    ],
                    "guid": "F*p6V*<MCH",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the span of a set of vectors?",
                        "<div>The set of all points obtainable by linear combination of the original vectors.</div>"
                    ],
                    "guid": "Q2K_[*jndk",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Under what conditions is a matrix invertible?",
                        "Option 1: The equation&nbsp;\\( A x=b\\) must have exactly one solution for every value of \\(b\\).<div><br></div><div><div>Option 2: \\(A\\) must be square and all the columns be linearly independent.</div></div><div><br></div><div>Option 3: \\(A\\) must be square and have a non-zero determinant.</div><div><br></div>"
                    ],
                    "guid": "MNEDc#dl44",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do you determine if&nbsp;\\(\\boldsymbol{A x}=\\boldsymbol{b}\\) has a solution?",
                        "<div>By testing whether b is in the span of the columns of A.&nbsp;</div><div>This particular span is known as the column space.</div>"
                    ],
                    "guid": "uf_+J2?7@Y",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a singular matrix?",
                        "<div><b>A square matrix with linearly dependent columns.</b></div><div><div>&nbsp;</div><div>If A is not square or is square but singular but cannot use the method of matrix inversion to find the solution.</div></div>"
                    ],
                    "guid": "z:fD,;&ez3",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the L\\(\\infty\\) (max) norm?",
                        "<div><div><div>The absolute value of the element with the largest magnitude in the vector</div></div></div><div><br></div><div>\\(\\|\\boldsymbol{x}\\|_{\\infty}=\\max _{i}\\left|x_{i}\\right|\\)<br></div>"
                    ],
                    "guid": "d.>s,KGH;.",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the frobenius norm?",
                        "A norm that measures the size of a matrix. It is analagous to the L2 norm.<div><br><div>\\(\\|A\\|_{F}=\\sqrt{\\sum_{i, j} A_{i, j}^{2}}\\)<br></div></div>"
                    ],
                    "guid": "P`Gj~@8~87",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a symmetric matrix?",
                        "Any matrix that is equal to its own transpose<div><br></div><div>\\(\\boldsymbol{A}=\\boldsymbol{A}^{\\top}\\)</div>"
                    ],
                    "guid": "Q=^?{.gLs5",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a unit vector?",
                        "A vector with unit norm<div><br></div><div>\\(\\|\\boldsymbol{x}\\|_{2}=1\\)<br></div>"
                    ],
                    "guid": "dJ9gU(lY.0",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What does it mean for two vectors to be orthogonal?",
                        "A vector \\(\\boldsymbol{x}\\) and a vector \\(\\boldsymbol{y}\\) are orthogonal to each other if \\(\\boldsymbol{x}^{\\top} \\boldsymbol{y}=0\\)"
                    ],
                    "guid": "i7E/M)-.O{",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is an eigendecomposition?&nbsp;",
                        "<div><div>\\(\\boldsymbol{A}=\\boldsymbol{Q} \\mathbf{\\Lambda} \\boldsymbol{Q}^{\\top}\\)<br></div></div><div><br></div><div><br></div>When we decompose a matrix into a set of eigenvectors and eigenvalues<div><br></div><div>\\(\\boldsymbol{A}=\\boldsymbol{V} \\operatorname{diag}(\\boldsymbol{\\lambda})&nbsp;\\boldsymbol{V}^{-1}&nbsp; \\)<br></div><div><br></div><div>Suppose that a matrix \\(A\\) has \\(n\\) linearly independent eigenvectors \\(\\left\\{\\boldsymbol{v}^{(1)}, \\ldots,\\right.\\)<br>\\(\\boldsymbol{v}^{(n)} \\}\\) with corresponding eigenvalues \\(\\left\\{\\lambda_{1}, \\ldots, \\lambda_{n}\\right\\} .\\)&nbsp;<br></div><div><br></div><div>can concatenate all eigenvectors to form matrix \\(\\boldsymbol{V}\\) with one eigenvector per column</div><div>and&nbsp; concatenate the eigenvalues to form a vector \\(\\boldsymbol{\\lambda}\\).</div><div><br></div><div><br></div><div>Not every matrix can be decomposed into eigenvalues and eigenvectors</div><div><br></div><div>if a matrix is not square, the eigendecomposition is not deﬁned<br></div><div><br></div><div><img src=\"paste-8bfceaac2074b90ce8e0d0159e4b17db64de1227.jpg\"><br></div>"
                    ],
                    "guid": "sOICBGN3S4",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is an eigenvector and an eigenvalue?",
                        "An eigenvector of a square matrix \\(\\boldsymbol{A}\\) is a non-zero vector \\(\\boldsymbol{v}\\) such that multiplication by&nbsp;\\(\\boldsymbol{A}\\) alters only the scale of&nbsp;&nbsp;\\(\\boldsymbol{v}\\)&nbsp;<div><br></div><div>\\(\\boldsymbol{A} \\boldsymbol{v}=\\lambda \\boldsymbol{v}\\)<br></div><div><br></div><div>The scalar \\(\\lambda\\) is known as the eigenvalue.</div><div><br></div><div>Geometrically can be interpretted as a special vector such that when this special vector is multiplied by A the vector remains on its own span, strectching the vector out.</div><div><br></div><div>If \\(\\boldsymbol{v}\\)&nbsp; is an eigenvector, then so is any rescaled vector \\(\\boldsymbol{sv}\\)&nbsp;</div>"
                    ],
                    "guid": "BdybX>5m^X",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the trace of a matrix?",
                        "Sum of all diagonal the entries of a matrix.<div>&nbsp;- =&nbsp; sum of the eigenvalues</div><div>&nbsp;- invariant to change of basis</div><div><br></div>"
                    ],
                    "guid": "OM(%ej+aV9",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the determinant?",
                        "determinant of a square matrix is equal to the product of the eigenvalues of the matrix.<div><br></div><div>The <b>absolute value of the determinant</b> can be thought of as a <b>measure of how much multipliction by a matrix expands or contracts space</b>. The area of the square/pallelogram formed by the basis vectors.</div><div><br></div><div><img src=\"paste-ade2b2cb3d57b49c456c1f821d28d4b2ff48fe8b.jpg\"><br></div><div><br></div><div><br></div><div><img src=\"B6B64759-8F5A-9942-A98F-FBE06805BDF7.png\"><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "m:_3rl)_&0",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the rank of a matrix?",
                        "The&nbsp;<strong>rank</strong>&nbsp;of a matrix is defined as&nbsp;<div><br></div><div>(a) the maximum number of&nbsp;linearly independent&nbsp;<i>column</i>&nbsp;vectors in the matrix&nbsp;</div><div><br></div><div>or&nbsp;</div><div><br></div><div>(b) the maximum number of linearly independent&nbsp;<i>row</i>&nbsp;vectors in the matrix.</div><div><br></div><div><div>For an&nbsp;<i>r</i>&nbsp;x&nbsp;<i>c</i>&nbsp;matrix,</div>If&nbsp;<i>r</i>&nbsp;is less than&nbsp;<i>c</i>, then the maximum rank of the matrix is&nbsp;<i>r</i>.</div><div>If&nbsp;<i>r</i>&nbsp;is greater than&nbsp;<i>c</i>, then the maximum rank of the matrix is&nbsp;<i>c</i>.<br></div>"
                    ],
                    "guid": "DK0i|+?mj@",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is conditioning/condition number of matrix",
                        "Conditioning of a matrix refers to how rapidly a function changes with respect to small changes in its inputs.<div><br></div><div>The condition number of a matrix is the ratio of the largest and smallest eigenvalues.</div><div><div>When this number is large, matrix inversion is particularly sensitive to error in the input.</div></div><div><br></div><div>function \\(f(\\boldsymbol{x})=\\boldsymbol{A}^{-1} \\boldsymbol{x} .\\) When \\(\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}\\) has an eigenvalue decomposition,<br></div><div>its condition number is given by</div><div><br></div><div>\\(\\max _{i, j}\\left|\\frac{\\lambda_{i}}{\\lambda_{j}}\\right|\\)<br></div><div><br></div>"
                    ],
                    "guid": "x_Z2]$>JV;",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In Linear Algebra, what is broadcasting?",
                        "For operations between tensors of mismatched dimensions (A@B), broadcasting is a way of expanding the dimensions of A by duplicating elements, to be compatible those of B (or vise versa).<div><br></div><div>e.g. multiplying a scalar by an array, or if something has a dimension of size 1, can still work. so if A=[[1],[2]] and B is a 2x2 matrix, can still multiply A*B and get each row of A multiplied into each row of B.</div>"
                    ],
                    "guid": "BT:8N.Y/-J",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are scalars, vectors, matrices, and tensors?",
                        "Scalars: single numbers<div>Vectors: 1d arrays</div><div>Matrices: 2d arrays</div><div>Tensors: generalized n-dimensional matrices.</div>"
                    ],
                    "guid": "j0=,X@69uy",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the rank of a tensor?",
                        "The rank of an n-dimensional tensor is n."
                    ],
                    "guid": "n5GmP#&bUl",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the Haramard product of two matrices? What is the corresponding numpy operation?",
                        "The Hadamard product of two matrices A and B is the elementwise product.<div>The corresponding numpy multiplication is *</div>"
                    ],
                    "guid": "Nn|#;HHT-d",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is an inverse matrix? What are two existance criteria?",
                        "The inverse of matrix \\(A\\) is the matrix&nbsp;<div>\\(A^{-1}\\) such that \\[AA^{-1} = A^{-1}A = \\mathbb{I}\\]</div><div><div>The matrix inverse exists for square matrices when</div><div>-&nbsp;determinant is non-zero,&nbsp;</div><div>- if \\(A \\in K^{nxn}\\): columns span \\(K^n\\)</div><div><br></div></div>"
                    ],
                    "guid": "fc@4,=5c|0",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How can one calculate the inverse of an invertible matrix?",
                        "<div>Gaussian elimination:</div><div>perform row reduction on the augmented matrix \\([A \\vert \\mathbb{I}]\\) to get something like \\([\\mathbb{I} \\vert B]\\). The resulting \\(B = A^{-1}\\)</div><div></div>"
                    ],
                    "guid": "jxI/<_#L>s",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How is the determinant of a square matrix calculated?",
                        "<div>Laplacian expansion by minors:<br></div><div><br></div>The determinant for matrix \\(A\\) has a value<br>\\(&nbsp; &nbsp; &nbsp;|A|=\\sum_{i=1}^{k} a_{ij}C_{ij}, \\)<br>with no implied summation over \\(j\\), and where \\(C_{ij}\\) (= \\(a^{ij}\\)) is the cofactor of \\(a_{ij}\\) defined by <br>\\(&nbsp; &nbsp; C_{ij}=a^{ij}=(-1)^{i+j} M_{ij},&nbsp; &nbsp; &nbsp;\\)<br>and \\(M_{ij}\\) is the minor of matrix \\(A\\) formed by eliminating row \\(i\\) and column \\(j\\) from \\(A\\).&nbsp;<div><br></div>"
                    ],
                    "guid": "k)m3^jFfYs",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are the characteristic polynomial and characteristic equation of a square matrix A?",
                        "The characteristic polynomial p(λ) of a square matrix \\(A\\) is the determinant \\(p(\\lambda) = \\vert \\mathbb{I}\\lambda - A \\vert\\).&nbsp;<div><br></div><div>The characteristic equation of \\(A\\) is&nbsp;</div><div>\\( \\vert \\mathbb{I}\\lambda&nbsp;- A \\vert =0\\),</div><div>and the values of \\(\\lambda\\) that solve this equation are the eigenvalues of A.</div>"
                    ],
                    "guid": "A6,%K]W+tD",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In linear algebra, what is a span?",
                        "The span of a set of vectors = all vectors that can be formed by a linear combination of vectors in that set."
                    ],
                    "guid": "z{+q^upJ&D",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is linear dependence?",
                        "A set of vectors is linearly dependent if it contains at least one vector that can be written as a linear combination of the other vectors in the set."
                    ],
                    "guid": "F)oe2Yv8rn",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Ax=b: when is there a unique solution?",
                        "If \\(A\\) is a square \\(n\\times n\\) matrix, then \\(Ax=b\\) has a unique solution for all \\(b\\) iff the only solution of \\(Ax=0\\) is \\(x=0\\).<div><br></div><div>\\(Ax=b\\) has a unique solution for a certain \\(b\\) iff \\(b\\) is a linear combination of the columns of \\(A\\).</div>"
                    ],
                    "guid": "h6R.`5gvM=",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Ax=b: what happens when A is fat or tall?",
                        "fat (and full row rank): regardless of b, at least one solution exists<div>fat (not full row rank): there exists a b for which system of equations is inconsistent</div><div><br></div><div>tall (full column rank): there is at most one unique b for which the system is consistent</div><div>tall (not full column rank): there are infinitely many solutions</div>"
                    ],
                    "guid": "l,vrPO,=sA",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are the 3 conditions that a norm must satisfy?",
                        "In a vector space \\(V\\) with scalar field \\(F\\),&nbsp; \\(p\\) is a norm if for all \\(a \\in F\\) and \\(\\vec{u}, \\vec{v} \\in V \\), \\(p\\) satisfies...<div><br><div>1. the triangle inequality (/ subadditivity):</div><div>\\(p(\\vec{u} + \\vec{v}) \\leq p(\\vec{u}) + p(\\vec{v})\\)&nbsp;</div><div><br></div><div>2.&nbsp; absolute homogenaity (/absolute scalability):</div><div>\\( p(a\\vec{v}) = |a| p(\\vec{v}) \\)</div><div><br></div><div>3. positive definiteness:</div><div>&nbsp;if \\(p(\\vec{v})=0\\), then \\(\\vec{v} = 0\\)</div></div>"
                    ],
                    "guid": "EQ&=JCWhLo",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In ML, when is an L1 norm preferred to an L2 norm?",
                        "L1 norm encourages sparsity -&gt; drives weights to zero."
                    ],
                    "guid": "y)[IMJo;?$",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the L0 norm?",
                        "The L0 \"norm\" \\( \\Vert \\vec{v} \\Vert_{0} \\) of a vector \\(\\vec{v}\\) is commonly defined as the number of nonzero elements of that vector.&nbsp;<div><br></div><div>But this function is not really a norm, since it is not absolutely homogenous: \\( \\Vert a \\vec{v} \\Vert_{0} = \\Vert \\vec{v} \\Vert_{0} \\neq a \\Vert \\vec{v} \\Vert_{0} \\) for \\(a \\neq 1 \\).<br></div>"
                    ],
                    "guid": "NW-^8bg:@V",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a diagonal matrix?",
                        "A matrix where all nonzero elements lie on the diagonal"
                    ],
                    "guid": "c,_K9SP>^0",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why is multiplication by a diagonal matrix computationally cheap?",
                        "Multiplying (another matrix) by a square diagonal matrix is the same as multiplying each row of the multiplicand matrix by the corresponding element of the diagonal. The n scalar-vector products are cheaper (O(n^2) operations) than a full matrix multiplication (naively O(n^3) operations)"
                    ],
                    "guid": "L*&<<Im;-:",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a vector space?",
                        "A vector space over a field \\( F \\) is a set&nbsp;\\( V \\)&nbsp;together with the operations for<div>vector addition</div><div>\\( + : V \\times V \\rightarrow V\\)&nbsp;</div><div><br></div><div>and scalar multiplication</div><div>\\( \\cdot : F \\times V \\rightarrow V \\)</div><div><br></div><div>and which satisfies a bunch of axioms...</div><div><br></div>"
                    ],
                    "guid": "P-7=IKz[8b",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the inverse of a diagonal matrix (and when does it exist)?",
                        "Inverses exist for square diagonal matrices where no diagonal elements are zero.&nbsp;<div>The inverse is another diagonal matrix where each diagonal element is the inverse of the corresponding element in the original matrix.</div>"
                    ],
                    "guid": "PGsLym>U-z",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a symmetric matrix?",
                        "A symmetric matrix is a square matrix that is equal to its transpose (symmetric wrt. main diagonal)"
                    ],
                    "guid": "z(e]Blx%#g",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a unit vector?",
                        "A unit vector is a vector with length one in a normed vector space"
                    ],
                    "guid": "g%BTDxX]y.",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "When are two vectors orthogonal?",
                        "Vectors are orthogonal when their dot product is zero"
                    ],
                    "guid": "kkF2$tGGU{",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "When are two vectors orthonormal?",
                        "Two vectors in a normed vector space are orthonormal when they are orthogonal and both have norm 1."
                    ],
                    "guid": "E~~VbHnw3c",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is an orthogonal matrix? What are three convenient properties?",
                        "A square matrix in \\(R^n\\) is orthogonal iff its columns constitute an orthonormal basis for \\(R^n\\) (with the standard L2 norm) \\( \\Leftrightarrow \\) its rows do.<div><br></div><div>Orthogonal matrices are the real-valued special case of complex unitary matrices.<br><div><br></div><div>Convenient properties for an orthogonal matrix \\(A\\):</div><div>1. \\(A^T = A^{-1}\\)</div><div>2. Determinant is either +1 or -1</div><div>3. Orthogonal matrices preserve dot products and thus act as isometries of euclidian space (rotations, reflections, rotoreflections).</div></div>"
                    ],
                    "guid": "eW<CDiJQE]",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are eigenvectors/eigenvalues?",
                        "The eigenvectors and eigenvalues of a matrix \\(A\\) are all the vectors \\(\\vec{v}\\) and scalars \\(\\lambda\\) that satisfy the equation<div>\\[ A \\vec{v} = \\lambda \\vec{v} \\]</div>"
                    ],
                    "guid": "2*>vUbgN@",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What happens when a matrix is applied to its eigenvectors?",
                        "A matrix elongates/shrinks its eigenvector by a factor given by the corresponding eigenvalue."
                    ],
                    "guid": "uG[}tf_uo2",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How many eigenvalues does a matrix have?",
                        "The characteristic equation of a matrix \\( A \\in R^{n} \\) is:<div>\\[ p(\\lambda) = det( A - \\lambda v) = 0 \\].</div><div>The number of distinct solutions \\( N_{\\lambda} : 1 \\leq N_{\\lambda} \\leq N \\) is the same as the number of eigenvalues.<br></div>"
                    ],
                    "guid": "Fba=]r>5=U",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the spectrum of a matrix?",
                        "The spectrum of a matrix is the set of its eigenvalues."
                    ],
                    "guid": "wL@v,!ItmZ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the eigendecomposition? When does it exist?",
                        "The eigendecomposition (also spectral decomposition) of a matrix \\(A\\) is the factorization<div>\\[ A = Q \\Lambda Q^{-1} \\],</div><div>where \\(Q\\) is a matrix of eigenvectors and \\(\\Lambda\\) is a diagonal matrix of the corresponding eigenvalues.</div><div><br></div><div>The eigendeomposition exists when \\(A\\) is square and diagonalizable.</div>"
                    ],
                    "guid": "k|G1-J9^&%",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How does the eigendecomposition of a matrix relate to its inverse?",
                        "If a matrix \\(A\\) is nonsingular (no zero eigenvalues), then its inverse is given by&nbsp;<div>\\[ A^{-1} = Q \\Lambda^{-1} Q^{-1} \\],&nbsp;</div><div>where \\(Q\\) and \\(\\Lambda\\) are from the eigendecomposition of A.</div>"
                    ],
                    "guid": "zyNn?8Lebb",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How can one calculate the eigenvalues of a matrix?",
                        "Find the solutions \\(\\lambda\\) to the characteristic equation of the matrix \\(A\\):<div>\\[ det(A - \\lambda I)&nbsp; = 0 \\]</div>"
                    ],
                    "guid": "P|/-5XF;GR",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "When is the eigendecomposition unique?",
                        "The eigendecomposition is unique when the eigenvalues are distinct."
                    ],
                    "guid": "E!1CDl3]ax",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do we represent degenerate eigendecompositions?",
                        "If the eigendecomposition of \\(A \\in R^n\\) is not unique (i.e. has repeated eigenvalues), then we associate with each eigenvalue a subspace of vectors \\(E_{\\lambda}\\) such that for all \\( \\vec{v} \\in E_{\\lambda} : A \\vec{v} = \\lambda \\vec{v} \\).<div><br></div><div>The space \\(R^n\\) is spanned by a set containing all unique eigenvectors + vectors spanning each of the \\(E_\\lambda\\)</div>"
                    ],
                    "guid": "v=nYJ#AACm",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are positive definite, negative definite, positive semi-definite, and negative semi-definite matrices?",
                        "- positive definite: the scalar \\(z^T M z \\) is strictly positive for every non-zero column vector z of real numbers<div>- positive semi-definite: same as above, but positive or zero</div><div><br></div><div>- negative definite: the scalar \\(z^T M z \\) is strictly negative for every non-zero column vector z of real numbers</div><div>- negative semi-definite: same as above, but negative or zero</div>"
                    ],
                    "guid": "PC<F#=1KM4",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the singular value decomposition?",
                        "SVD factorization of \\(M \\in Z^{m\\times n}\\):<div>\\( M = U \\Sigma V^{*} \\),&nbsp;</div><div>where&nbsp;</div><div>- \\(U \\in Z^{m\\times m}\\) is unitary,&nbsp;</div><div>- \\(\\Sigma \\in R^{m\\times n}\\) is (rectangular) diagonal with non-zero values,</div><div>- \\( V \\in Z^{n\\times n} \\) is unitary.</div><div><br></div><div>columns of \\( U\\): left singular vectors</div><div>columns of \\( V\\): right singular vectors</div><div>(diagonal) values in \\(\\Sigma\\): singular values</div><div><br></div><div>If \\(M\\) is real valued, then \\(U\\) and \\(V\\) are real/orthogonal matrices.</div>"
                    ],
                    "guid": "m`G8WD+.+C",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How does SVD compare to eigendecomposition? (3 ways)",
                        "<div>SVD: \\( M = U \\Sigma V^* \\)</div><div>Eigen: \\( M = Q \\Lambda Q^T \\)</div>- \\(U, V\\) are unitary (orthogonal if real) so they represent isometries (rotations/flips)<div>- \\(U, V\\) generally bear no relation while \\(Q, Q^T\\) are transposes of one another</div><div>- SVD always exists, while eigendecomposition only exists for some square matrices.</div>"
                    ],
                    "guid": "J-Xr0(Oj$>",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How is the SVD calculated?",
                        "SVD:<div>\\[ A_{n\\times p} = U_{n \\times n} S_{n\\times p} V^{T}_{p\\times p} \\].</div><div>Columns of U = eigenvectors of \\( AA^T \\),</div><div>Columns of V = eigenvectors of \\(A^T A\\).</div><div><br></div><div>The non-zero elements of S are the square roots of the non-zero eigenvalues of \\( AA^T \\) (or \\(A^T A\\) ).</div><div><br></div><div>The SVD is not unique, but the SVD-with-sorted-S is.</div>"
                    ],
                    "guid": "wx@q>iKL;l",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why are singular values non-negative?",
                        "If \\(A\\) has real entries then \\(A^T A\\) is positive semidefinite, since \\( \\langle A^T A \\vec{v}, \\vec{v} \\rangle = \\langle A \\vec{v}, A\\vec{v} \\rangle \\geq 0 \\).&nbsp;<div>Since \\(A^T A\\) is positive semidefinite, its eigenvalues (= singular values of A) are non-negative.</div>"
                    ],
                    "guid": "GT{gVj/zcs",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the Moore Penrose pseudoinverse?",
                        "<div><b>Moore Penrose pseudoinverse</b><br></div><div><b><br></b></div><div>Generalizes the regular inverse to rectangular and non invertible matrices.<br></div><div>\\( A^+ = A^* (A A^*)^{-1} \\)<br></div><div><br></div><div>- When A is invertible, \\(A^{-1} = A^+\\).</div><div>- \\((A^+)^+ = A\\).</div><div><br></div><div>Best way to calculate is via SVD; \\(A\\) is \\(A^+= V&nbsp; D^+&nbsp; U^T\\)<div>where \\(U, V\\) are from the SVD and \\(D^+\\) is the pseudoinverse of \\(S = 1/S\\).</div><div><br></div></div><div>Special case for vectors \\(\\vec{x}\\):<div>\\(\\vec{x}^+ = \\vec{x}^T\\) if \\( \\vec{x} = 0 \\). Otherwise,</div><div>\\(\\vec{x}^+ = \\vec{x}^* / (\\vec{x}^*\\vec{x}) \\)</div></div>"
                    ],
                    "guid": "zw0KEbH/w?",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How can the Frobenius norm be written in terms of a trace?",
                        "\\[ \\Vert A \\Vert_{F} = \\sqrt{\\text{Tr}(A A^*)}\\]"
                    ],
                    "guid": "BLp~zYsR5S",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the condition number of a matrix? What is an ill-conditioned matrix?",
                        "For a matrix \\(A\\) in a complex vector space with euclidian norm, the condition number \\(\\kappa(A)\\) is the ratio between the largest and smallest singular values.<br><div><br></div><div>An ill-conditioned matrix is one with a large condition number. Ill-conditioned matrices( \\(\\kappa \\approx 10^14) \\) for float32 ) are practically non-invertible, even if they are technically not singular.</div>"
                    ],
                    "guid": "L0z;l#q(Be",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a Jacobian matrix? What do the rows represent?",
                        "The jacobian of a multivariate function \\(F\\) is&nbsp;<div>\\[ J_{i, j} = \\frac{\\partial F_{i}}{\\partial x_{j}} \\].</div><div><br></div><div>Each row is the gradient of a single component&nbsp; of \\(F\\).<br></div>"
                    ],
                    "guid": "K,SW3y0M[f",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a Hessian matrix?&nbsp;",
                        "The hessian \\( H f \\) of \\( f: R^n \\rightarrow R \\) is a symmetric square \\( n \\times n \\) matrix with elements:&nbsp;<div><br><div>\\( (H f)_{i,j} = \\frac{\\partial^2 f}{\\partial x_{i} \\partial x_{j}} \\)</div></div><div><br></div>"
                    ],
                    "guid": "EtwGqrEui;",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "<div>What are the \\(L_{1}\\), \\(L_{2}\\), and \\(L_{\\infty}\\) norms?<br></div>",
                        "<div>Suppose we have a vector \\(\\vec{x}\\) in an \\(N\\)-dimensional vector space: \\( \\vec{x} = \\sum_{i=1}^{N} x_{i} \\hat{e}_{i} \\).</div><div><br></div><div>\\(L_{1}\\) norm: manhattan/taxicab distance</div><div>\\(\\Vert \\vec{x} \\Vert_{1} = \\sum_{i=1}^{N} |x_{i}| \\)</div><div><br></div><div><div>\\(L_{2}\\) norm: euclidian/straight line distance</div>\\(\\Vert \\vec{x} \\Vert_{2} = \\sqrt{\\sum_{i=1}^{N} x_{i}^{2}} \\)</div><div><br></div><div><div>\\(L_{\\infty}\\) \"norm\":&nbsp; length of longest component (not a real norm)</div>\\(\\Vert \\vec{x} \\Vert_{\\infty} = \\max\\left(|x_{1}|, |x_{2}|, \\ldots, |x_{N}| \\right) \\)</div><div><br></div>"
                    ],
                    "guid": "M<Ox]F1o1p",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a metric? (3 requirements)",
                        "<div><u><b>Metric</b></u><br></div><div><div><div>A distance function \\(d: X&nbsp; \\times X&nbsp; \\rightarrow \\left[ 0, \\infty \\right) \\) is a metric on the set \\( X \\)&nbsp; if it satisfies the following for all points&nbsp; \\( x, y, z \\in X \\)&nbsp;</div><div>&nbsp;</div><div>1. \\(d(x, y)=0 \\Rightarrow x=y\\)<br></div><div>2. \\( d(x, y) =&nbsp; d(y, x)\\)</div><div>3.&nbsp;\\(d(x, y) \\leq d(x, z)+d(y, z)\\)</div><div><br></div><div>These rules are very general and<b>&nbsp;can be used to create</b>&nbsp;<b>useless metrics</b></div><div><br></div><div><br></div></div><div><br></div></div>"
                    ],
                    "guid": "x$<z_wEC}h",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What's the complexity of multiplying matrices of size \\(n\\times m\\) and \\(m \\times p\\)?",
                        "<div>\\(\\mathcal{O}(nmp)\\)</div><div><br></div>"
                    ],
                    "guid": "ryB,%1O80{",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a normal matrix?",
                        "\\(A\\) is normal if:<div>\\(A A* = A* A\\)</div><div><br></div><div>e.g. it commutes with its (conjugate) transpose)<br><div><br></div></div>"
                    ],
                    "guid": "l/*?Bt{E6Q",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What does the spectral theorem state?",
                        "A matrix is normal iff. it is unitarily similar to a diagonal matrix, e.g.<div>\\(A = P^{-1} B P\\) for unitary \\(P\\) and a diagonal \\(B\\).</div>"
                    ],
                    "guid": "za8:N~Ua<O",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a unitary matrix?",
                        "For reals: \\(A^T A = A A^T = I\\)<div>(conjugate transpose for complex square matrices)</div>"
                    ],
                    "guid": "AWlzBhD3;6",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "When are all eigenvalues positive and real",
                        "Matrix is<b> real and symmetric</b>"
                    ],
                    "guid": "E$^KYEl=x!",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the Schur decomposition?",
                        "\\[ A = Q U Q^{-1} \\],&nbsp;<div>where \\(Q\\) is a unitary matrix \\((Q^{-1} = Q^{*})\\) and U is upper triangular</div>"
                    ],
                    "guid": "GOs`)O?ijY",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "When is one matrix similar to another?",
                        "\\(A\\) and \\(B\\) are similar if there exists an invertible matrix \\(P\\) (\"change of basis\") such that&nbsp;<div>\\[B = P^{-1} A P\\]</div>"
                    ],
                    "guid": "sx;-E=/1o?",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the kernel of a linear map?",
                        "if \\(f: V \\rightarrow W\\) is linear, the kernel of \\(f\\) is:<div>\\[\\text{ker}(f) = \\left\\lbrace x \\in V : f(x) = 0 \\right\\rbrace\\]</div>"
                    ],
                    "guid": "Di&)~ZU;.q",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the image of a linear map",
                        "if \\(f: V \\rightarrow W\\) is linear, the image of \\(f\\) is:<div>\\[\\text{ker}(f) = \\left\\lbrace w \\in W : w = f(x), x \\in V \\right\\rbrace \\]</div>"
                    ],
                    "guid": "JNkb`5-8O7",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the rank-nullity theorem?",
                        "<div>if \\(f : V \\rightarrow W\\) is a linear map,&nbsp;</div>\\[\\text{dim}(\\text{ker}(f)) + \\text{dim}(\\text{im}(f)) = \\text{dim}(V)\\]"
                    ],
                    "guid": "j#c7lP0i+g",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the rank of a linear map?",
                        "\\(\\text{dim}(\\text{im}(f))\\)"
                    ],
                    "guid": "Jh%XM(n+c(",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the nullity of a linear map?",
                        "\\text{dim}(\\text{ker}(f))"
                    ],
                    "guid": "r(D0h$RP9M",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a group?",
                        "Group: \\(G := (\\mathcal{G}, \\otimes) \\) is a group if the set \\(\\mathcal{G}\\) and operation \\(\\otimes\\) satisfy...<div>&nbsp;1. <b>Closure </b>of&nbsp;\\(\\mathcal{G}\\) under \\(\\otimes\\):&nbsp;</div><div>\\( \\forall x, y \\in \\mathcal{G}: x \\otimes y \\in \\mathcal{G} \\)</div><div>&nbsp;2. <b>Associativity:</b>&nbsp;</div><div>\\( \\forall x,y,z \\in \\mathcal{G}: (x \\otimes y) \\otimes z = x \\otimes (y \\otimes z) \\)</div><div>&nbsp;3. <b>Identity:</b>&nbsp;</div><div>\\( \\exists&nbsp; e \\in \\mathcal{G}, \\forall x \\in G : x \\otimes e = x \\text{ and } e \\otimes x = x \\)</div><div>&nbsp;4. <b>Inverse:</b></div><div>\\( \\forall x \\in \\mathcal{G}, \\exists y \\in G : x \\otimes y = e \\text{ and } y \\otimes x = e \\)</div><div>5. (optional, Abelien groups) <b>Commutativity</b>:</div><div>\\( \\forall x, y \\in G: x \\otimes y = y \\otimes x \\)</div>"
                    ],
                    "guid": "mX=o}&:b])",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "4279acd4-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "4279afa4-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "300px-Overfitting.svg.png",
                "Screenshot 2019-05-15 at 10.52.43.png",
                "Screenshot 2019-05-21 at 14.31.26.png",
                "paste-265207c24bbf964d9daafaa91d34558e2c1fc322.jpg",
                "paste-63f752e62670d3995dd9651fe0ba2659057332a8.jpg",
                "paste-a6e354dc73aa9cf0e6ff9a8bd11025d680b6cca1.jpg",
                "paste-b59b6fd9e8bdc633f1e2ebfe40ec6c367e53ccba.jpg",
                "paste-c8ad6fc738f279895b0f1ee6e49b75762b5fda07.jpg"
            ],
            "name": "machine_learning",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "Name 5 Clustering Algorithms",
                        "K Means<div><br></div><div>Gaussian Mixture Models</div><div><br></div><div>Mean Shift</div><div><br></div><div>DBSCAN</div><div><br></div><div>Unsupervised NN&nbsp;</div>"
                    ],
                    "guid": "w$H0T2yj%V",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the curse of dimensionality?",
                        "<div>The volume of a region of space&nbsp;(~number of cells in that space) grows exponentially with the dimensionality of the input space.</div><div><br></div><div>The large number of cells means that we need an exponentially large quantity of data to ensure all cells are represented in a dataset.</div><div><br></div><div><br></div><img src=\"Screenshot 2019-05-15 at 10.52.43.png\">"
                    ],
                    "guid": "JLZepf0AU&",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do we overcome the curse of dimensionality?",
                        "Real data is often confined to a manifold<div><br></div><div>Real data often exhibits smoothness (at least locally), meaning that a small change in the input will produce a small change in the target variables.</div>"
                    ],
                    "guid": "Q]S~S(==%<",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is overfitting?",
                        "<div>Overfitting happens when a model learns noise and spurious details in the training data to the extent that it negatively impacts the performance of the model on new data.<br></div><div><br></div><div>This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model.&nbsp;<br></div><div><br></div><div><img src=\"300px-Overfitting.svg.png\"><br></div>"
                    ],
                    "guid": "lSLM[7qokW",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is a generative model?",
                        "A generative model learns a joint probability distribution.&nbsp;<div><br></div><div><br></div><div>Example,&nbsp;</div><div><br></div><div>Build a model of what dogs look like p(x|y=0)</div><div><br></div><div>Build a model of what elephants look like p(x|y=1)</div><div><br></div><div>To classify a new animal we can match the new animal against the model of the dogs and the model of the elephants, choose the most likely one p(y|x)</div><div><br></div><div>A gaussian process is an example of a generative model</div><div><br><div><img src=\"paste-c8ad6fc738f279895b0f1ee6e49b75762b5fda07.jpg\"><br></div></div>"
                    ],
                    "guid": "P$H)TfIgu}",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Name 5 Classification Algorithms",
                        "Logistic Regression<div><br></div><div>MLPs</div><div><br></div><div>NN</div><div><br></div><div>Random Kitchen Sink</div><div><br></div><div>Regression Trees</div><div><br></div>"
                    ],
                    "guid": "!I58rvItS",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are parametric models?",
                        "Assume some finite set of parameters \\(\\theta \\).<div><br></div><div><b>Given the parameters, future predictions, \\(x\\), are independent of the observed data&nbsp;\\(\\mathcal{D}\\):</b></div><div><br></div><div>\\(P(x | \\theta, \\mathcal{D})=P(x | \\theta)\\)<br></div><div><br></div><div>therefore&nbsp;\\(\\theta \\) <b>captures everything&nbsp;there is to know about the data</b>.</div><div><br></div><div><b>Complexity of the model is bounded </b>even if the amount of data is unbounded.&nbsp;This makes them <b style=\"\">not very flexible</b>.<br></div><div><br></div><div><u>Examples</u></div><div>polynomial regression (Function approximation)<u><br></u></div><div>logistic regression (Classification)<br></div><div>mixture models, k-means (Clustering)<br></div>"
                    ],
                    "guid": "FzNAD[Gp2K",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are non-parametric models?",
                        "<b>Assume that the data distribution cannot be defined in terms of such a finite set of parameters.</b><div><br></div><div>But they can often be defined by assuming an infinite dimensional&nbsp;\\(\\theta \\). Usually we think of&nbsp; \\(\\theta \\) as a function.<br></div><div><br></div><div>The <b>amount of information that &nbsp;\\(\\theta \\) can capture about the data D can grow as the amount of data grows.</b> This makes them<i> more flexible</i>.</div><div><br></div><div><u>Examples</u></div><div>Gaussian processes (Function approximation)<u><br></u></div><div>Gaussian process classifiers (Classification)<br></div><div>Dirichlet process mixtures (Clustering)<br></div>"
                    ],
                    "guid": "HS_H1P<~_S",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the no free lunch theorem?",
                        "<div><b>Any two algorithms are equivalent when their performance is averaged across all possible problems.</b></div><div><br></div><div><div>The most sophisticated algorithm we can conceive of has the same average performance (over all possible tasks) as merely predicting that every point belongs to the same class.</div></div>"
                    ],
                    "guid": "Fn(lo{,RYx",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is dimensionality reduction?",
                        "The process of reducing the dimension of your feature set.<div><br></div><div>Feature selection is the process of identifying and selecting relevant features for your sample.<br></div><div><br></div><div>Feature engineering is manually generating new features from existing features.<br></div><div><br></div><div><u>Methods</u></div><div><u><br></u></div><div>PCA (Linear): PCA rotates and projects data along the direction of increasing variance. The features with the maximum variance are the principal components.</div><div><br></div><div>t-SNE (Non-Linear):&nbsp;Computes the probability that pairs of data points in the high-dimensional space are related and then chooses a low-dimensional embedding which produce a similar distribution.</div><div><br></div><br>"
                    ],
                    "guid": "dkG:&<hG+Q",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a Markov Decision Process (MDP)?",
                        "<img src=\"paste-b59b6fd9e8bdc633f1e2ebfe40ec6c367e53ccba.jpg\"><div><br></div><div><img src=\"Screenshot 2019-05-21 at 14.31.26.png\"><br><div><br></div><div><br></div></div>"
                    ],
                    "guid": "C*jTW7kacC",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "When does logistic regression give you the optimal solution?",
                        "When the data are separable, the optimum is at infinity, so you will never reach it.<div>Normally, though, any optimization algorithm you are using will reach a point from which no noticeable improvement can be attained by iterating further.</div>"
                    ],
                    "guid": "sPYpg(Um.q",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is teacher forcing?",
                        "<div><b>Teacher forcing works by using the actual or expected output from the training dataset at the current time step y(t) as input in the next time step X(t+1), rather than the output generated by the network.</b><br></div><div><br></div><div>Alternative to backpropagation through time.<br></div><div><br></div><div>If model starts of wrong it messes up for all other time steps. So instead of feeding in the model prediction you feed in the ground truth.</div><div><br></div><div>This approach can also result in models that may be fragile or limited when used in practice when the generated sequences vary from what was seen by the model during training.<br></div><div><br></div><div><img src=\"paste-a6e354dc73aa9cf0e6ff9a8bd11025d680b6cca1.jpg\"><br></div>"
                    ],
                    "guid": "A!YYj2}CcU",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What properties of the L1 norm are useful?",
                        "<div>Minimizing the L1 norm encourages sparsity, so it is commonly used&nbsp;when the diﬀerence between zero and nonzero elements is very important.</div><div>- Every time an component of \\(x\\) moves away from 0 by $\\epsilon$, the L1 norm increases by $\\epsilon$.</div><div>- Grows at the same rate in all locations.<br></div>"
                    ],
                    "guid": "IqQ4~20cKU",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Name three possible sources of uncertainty in ML",
                        "1. <b>Inherent stochasticity in the system being modeled</b><div><br><div>2. <b>Incomplete observability&nbsp;</b></div><div>&nbsp; &nbsp; Even deterministic systems can appear stochastic when we cannot observe all the variables that drive the behavior of the system.</div><div><br></div><div>3. <b>Incomplete modelling</b></div></div><div><div>&nbsp; &nbsp; When we use a model that must discard some of the information we have observed, the discarded information results in uncertainty in the model’s predictions.</div></div>"
                    ],
                    "guid": "NH<;F4{8{.",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a gaussian mixture model?",
                        "Components \\(p(\\mathbf{x} | \\mathbf{c}=i)\\) are Gaussians.<br><div>Each component has a separately parametrized mean and covariance.</div><div><br></div><div>Is a <b>universal approximator</b> of densities&nbsp;</div><div><br></div><div><div>any smooth density can be approximated with any speciﬁc nonzero amount of error by a Gaussian mixture model with enough components.</div></div>"
                    ],
                    "guid": "veXbu88HXQ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is the softplus function?",
                        "\\(f(x)=\\log (1+\\exp (x))\\)<div><br></div><div>Can be useful for producing&nbsp;the \\(\\beta\\) or \\(\\sigma\\) parameter of a normal distribution its range is&nbsp;\\((0, \\infty)\\).</div><div><br></div><div><img src=\"paste-265207c24bbf964d9daafaa91d34558e2c1fc322.jpg\"><br></div>"
                    ],
                    "guid": "gyRGTL#(mq",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is generalization",
                        "The ability to perform well on previously unobserved inputs"
                    ],
                    "guid": "b,&Mkf@XWF",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what are the i.i.d assumptions ?",
                        "<b>Examples in each dataset</b> are <b>independent</b>&nbsp;from each other, and that the <b>training and the test set are identically distribution</b>"
                    ],
                    "guid": ";0GY&[2$+",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is a hypothesis space?",
                        "<div>The set of functions that the learning algorithm is allowed to select as being the solution&nbsp;</div>"
                    ],
                    "guid": "l?rBJb<{(l",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe nearest neighbour regression",
                        "<div>Non parametric</div><div><br></div><div>Stores the X and y from the training set</div><div><br></div><div><div>to classify a test point x, the model looks up the nearest entry in the training set and returns the associated regression target.</div></div><div><br></div><div>In other words \\(, \\hat{y}=y_{i}\\) where \\(i=\\arg \\min \\left\\|\\boldsymbol{X}_{i, ;}-\\boldsymbol{x}\\right\\|_{2}^{2}\\)<br></div>"
                    ],
                    "guid": "rcqjqoHLy|",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe Bagging&nbsp;",
                        "<div>The idea is to train several diﬀerent models separately, then have all the models vote on the output for test examples.</div><div><br></div><div><img src=\"paste-63f752e62670d3995dd9651fe0ba2659057332a8.jpg\"><br></div>"
                    ],
                    "guid": "k<[Bj5|`E",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why is MSE preferred to L2 norm in ML? (3 reasons)",
                        "- smoother gradients<div>- computational simplicity</div><div>- assuming gaussian noise, minimizing MSE is the same as minimizing variance</div>"
                    ],
                    "guid": "KuZ:3}e489",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "427a024c-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "427a0544-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "paste-c3fc6b993051cd10ade100875a36ddde8d94c301.jpg"
            ],
            "name": "optimization",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the objective function?",
                        "The function we wish to minimise or maximise"
                    ],
                    "guid": "BVoB.dMx27",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are Batch/Deterministic gradient methods?",
                        "Optimization algorithms that process all the training examples simultaneously in a large batch.&nbsp;<div><br></div><div>We often mixup terminology for batch and minibatch. e.g. should be minibatch size instead of batch size.</div>"
                    ],
                    "guid": "d)#wX#Xduv",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why is it important that mini batches are selected randomly?",
                        "We are using mini batches to <b>compute an unbiased estimate of the expected value of the gradient</b>, this <b>requires independent samples</b>. So we can get in<b>dependent gradient estimates</b>."
                    ],
                    "guid": "N|Kf,u.7z3",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How does ill-conditioning of the Hessian affect optimization?",
                        "<div><b>Ill-conditioning can manifest by causing SGD to get “stuck” in the sense that even very small steps increase the cost function</b></div><div><br></div><div><div>Taylor series expansion of the cost function predicts that a gradient descent step of \\(−\\epsilon g\\) will add&nbsp;\\(\\frac{1}{2} \\epsilon^{2} \\boldsymbol{g}^{\\top} \\boldsymbol{H} \\boldsymbol{g}-\\epsilon \\boldsymbol{g}^{\\top} \\boldsymbol{g}\\) to the cost</div></div><div><br></div><div><div>The result is that <b>learning becomes very slow despite the presence of a strong gradient</b> because the learning rate must be shrunk to compensate for even stronger curvature.</div></div><div><br></div>"
                    ],
                    "guid": "HTf=zG-kyK",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "numerical_analysis",
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe gradient clipping",
                        "<b>When gradient descent proposes making a very large step it reduces the step size making it less likely to go outside the region of steepest descent.</b><div><br></div><div><div>Recall that the gradient speciﬁes not the optimal step size, but only the optimal direction within an inﬁnitesimal region.</div></div>"
                    ],
                    "guid": "EBlB4q{J%U",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What causes steep cliffs in cost functions?",
                        "<b>Multiplication of multiple large weights</b> causes extremely steep regions.&nbsp;<div><br></div><div><div>Cliﬀ structures are most common in the cost functions for recurrent neural networks.&nbsp;</div><div><div>Such models involve a multiplication of many factors, with one factor for each time step.</div></div><div><br></div><div><img src=\"paste-c3fc6b993051cd10ade100875a36ddde8d94c301.jpg\"><br></div></div>"
                    ],
                    "guid": "c50(=c;+v9",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the exploding and vanishing gradient problem&nbsp;",
                        "<div>Suppose that a computational graph contains a path that consists of repeatedly multiplying by a matrix W<br></div><div><br></div><div><div>After t steps, this is equivalent to multiplying by&nbsp;\\(\\boldsymbol{W}^{t}\\) therefore&nbsp;</div><div><br></div><div>\\(\\boldsymbol{W}^{t}=\\left(\\boldsymbol{V} \\operatorname{diag}(\\boldsymbol{\\lambda}) \\boldsymbol{V}^{-1}\\right)^{t}=\\boldsymbol{V} \\operatorname{diag}(\\boldsymbol{\\lambda})^{t} \\boldsymbol{V}^{-1}\\)<br></div><div><br></div><div><b>Any eigenvalues&nbsp;</b>\\(\\lambda_{i}\\) t<b>hat are not near an absolute value of 1&nbsp;</b></div><div><b><br></b></div><div><b>will&nbsp;</b><b><u>explode</u> if they are greater than 1</b></div><div><b><br></b></div><div><b>will </b><u style=\"font-weight: bold;\">vanish</u>&nbsp;<b>if they are less than 1 in magnitude</b></div></div>"
                    ],
                    "guid": "eZA]_mf|Wh",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the problem caused by vanishing gradients?",
                        "Vanishing gradients make it diﬃcult to know which direction the parameters should move to improve the cost function"
                    ],
                    "guid": "FD0lR2{!g6",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": [
                        "optimization"
                    ]
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is line search?",
                        "Line search: strategy for finding local minima of a function.&nbsp;<div>Algorithm:</div><div>1. Find a descent direction (i.e. -grad)</div><div>2. Compute a step size to determine how far to step.</div>"
                    ],
                    "guid": "mu,[h%#Hqt",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "427a319a-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "427a3442-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "220px-Discrete_probability_distrib.svg.png",
                "220px-Graph_model.svg.png",
                "325px-Exponential_pdf.svg.png",
                "325px-Laplace_pdf_mod.svg.png",
                "325px-Poisson_pmf.svg.png",
                "IMG_4739.jpg",
                "Screenshot 2019-06-05 at 19.58.41.png",
                "happy-sampler.png",
                "paste-3451c5f80050ab22009ad19e29b7e44763e520c1.jpg",
                "paste-4358772adc09fae166f662c262063f4594bbba71.jpg",
                "paste-58824f51988fbb4c7e50e3d47723f0701a94d99c.png",
                "paste-6d4c5c108ea13458b0d3a202cab3486963b2a11b.jpg"
            ],
            "name": "probability",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a probability density function?",
                        "A PDF is a probability distribution for a continuous random variable.<div><br></div><div>Used to&nbsp;<b>specify the</b>&nbsp;<b>probability of the&nbsp;random variable&nbsp;falling&nbsp;<i>within a particular range of values</i>,</b>&nbsp;as opposed to taking on any one value<br></div><div><br></div><div><div>If the probability of a real-valued variable x falling in the interval (x, x + δx) is given by p(x)δx for δx → 0, then</div> <div>p(x) is called the probability density over x.</div></div><div><br></div><div><div><br></div><div><br></div></div>"
                    ],
                    "guid": "ppDuzZsc)N",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is probability mass function?",
                        "<div>A function that gives the probability that a&nbsp;discrete random variable&nbsp;is exactly equal to some value.<br></div><div><br></div><div><img src=\"220px-Discrete_probability_distrib.svg.png\"><br></div>"
                    ],
                    "guid": "d=,dy7?8pB",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is variance?",
                        "Variance measures how far a set of (random) numbers are spread out from their average value<div><br></div><div>The variance gives a measure of how much the values of a function of a random variable<b> \\(X\\) </b>vary as we sample different values of \\(x\\) from its probability distribution</div><div><br></div><div>\\(\\operatorname{Var}(X)=\\mathrm{E}\\left[(X-\\mu)^{2}\\right]\\)</div><div><br></div><div><br></div><div><div>When the variance is low, the values of f(x) cluster near their expected value.</div></div><div><br></div><div><img src=\"IMG_4739.jpg\"><br></div>"
                    ],
                    "guid": "I-ePhd}I&]",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is covariance?",
                        "<div>The extent to which two random variables vary together</div><div><br></div><div>If the values of the variable tend to show similar behaviour as values of the other variable the covariance is positive. Otherwise the covariance is negative.</div><div><br></div><div>\\(Cov(X, Y)=\\mathrm{E}[X Y]-\\mathrm{E}[X] \\mathrm{E}[Y]\\)<br></div><div><br></div>"
                    ],
                    "guid": "HZ&ihKieA9",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is correlation?",
                        "<div>\\(\\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sqrt{\\operatorname{Var}(X) \\operatorname{Var}(Y)}}\\)<br></div><div><br></div><div>Covariance Normalized</div><div><br></div><div><u>Intuition:</u></div><div><br></div><div><img src=\"happy-sampler.png\"><br></div><div>The only real difference between the 3 Random Variables is just a constant multiplied against their output, but we get very different Covariance between any pairs.<br></div><div>\\(\\operatorname{Cov}(A, B)=2.5, \\operatorname{Cov}(A, C)=25, \\operatorname{Cov}(B, C)=250\\)<br></div><div><br></div><div>Our Covariance function doesn't have enough information to tell us that effectively A,B, and&nbsp;C are the same.</div><div>The problem is that we are no longer accounting for the Variance of each individual Random.&nbsp;The way we can solve this is to add a normalizing term that takes this into account.<br></div><div><br></div><div><br></div><div><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "KxguV604e[",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is bayes rule?",
                        "Bayes’ theorem converts the results from your test into the real probability of the event.<div><strong><br></strong></div><div>\\(P(A | B)=\\frac{P(B | A) P(A)}{P(B)}\\)<strong><br></strong></div><div><br></div><div>Where \\(A and B \\) are events and&nbsp;\\(P(B) \\neq 0 \\).</div><div><br></div><div>\\(P(A | B)\\) is a conditional probability: the likelihood of A occurring given that B is true. <b>Posterior</b>, degree of belief having accounted for B.</div><div><br></div><div>\\(P(B| A)\\) is also a conditional probability: the likelihood of event B occurring given that A is true.&nbsp;<br></div><div><br></div><div>\\(P(A)\\) and \\(P(B)\\) are the probabilities of observing&nbsp;\\(A\\) and&nbsp;\\(B\\) independently of each other. <b>Prior, </b>the initial degree of belief&nbsp; in A.</div><div><br></div><div><img src=\"paste-6d4c5c108ea13458b0d3a202cab3486963b2a11b.jpg\"><br></div><div><br></div>"
                    ],
                    "guid": "M7%[)Bpv*c",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is a random variable?",
                        "A random variable is a variable that can take on different values randomly."
                    ],
                    "guid": "FC2=o*38jt",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is the joint probability?",
                        "<div>The probability that X will take the value xi and Y will take the value yj</div><div><br></div><div><div>It is given by the number of points falling in the cell i,j as a fraction of the</div> <div>total number of points, and hence</div></div><div><br></div><div>\\(p\\left(X=x_{i}, Y=y_{j}\\right)=\\frac{n_{i j}}{N}\\)<br></div><div><br></div><div><img src=\"paste-3451c5f80050ab22009ad19e29b7e44763e520c1.jpg\"><br></div>"
                    ],
                    "guid": "j*#1Wo9R|T",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the sum rule for conditional probability?",
                        "<div><div>Given \\(P(X, Y)\\), \\(P(X=x_{i})\\) irrespective of the value of \\(Y\\) is given by the fraction of the total number of points that fall in column \\(i\\), e.g.</div></div><div><br></div><div>\\(P\\left(X=x_{i}\\right)=\\frac{c_{i}}{N}\\)<br></div><div><br></div><div>where&nbsp;\\(c_{i}=\\sum_{j} n_{i j}\\)&nbsp;</div><div><br></div><div>Which becomes</div><div><br></div>\\(P\\left(X=x_{i}\\right)=\\sum_{j=1}^{L} P\\left(X=x_{i}, Y=y_{j}\\right)\\)<div><br></div><div><br></div>"
                    ],
                    "guid": "hFu%f);ZIO",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is the conditional probability?",
                        "<div>If we consider only those instances for which X = \\(x_{i}\\), then the fraction of such instances for which Y = yj, written as&nbsp;\\(p\\left(Y=y_{j} | X=x_{i}\\right)\\)</div><div><br></div><div><div>It is obtained by finding the fraction of those points in column i that fall in cell i,j and hence is given by</div></div><div><br></div><div>\\(p\\left(Y=y_{j} | X=x_{i}\\right)=\\frac{n_{i j}}{c_{i}}\\)</div>"
                    ],
                    "guid": "N~G,,D}H@V",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is expectation of some function f(x) with respect to a probability distribution P(x)?",
                        "The average/mean value that f takes on when x is drawn from P<div><br></div><div><u>Discrete:</u></div><div>\\(\\mathbb{E}_{\\mathbf{x} \\sim P}[f(x)]=\\sum_{x} P(x) f(x)\\)<u><br></u></div><div><br></div><div><u>Continuous:</u></div><div>\\(\\mathbb{E}_{\\mathbf{x} \\sim p}[f(x)]=\\int p(x) f(x) d x\\)<u><br></u></div><div><br></div><div><div>By default, we can assume that E[·] averages over the values of all the random variables inside the brackets.</div></div><div><br></div>"
                    ],
                    "guid": "u~47dB,>lm",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "define the covariance matrix",
                        "The covariance matrix of a random vector \\(x \\in \\mathbb{R}^{n}\\) is an \\(n \\times n\\) matrix, such<br>that<div><br><div>\\(\\operatorname{Cov}(\\mathbf{x})_{i, j}=\\operatorname{Cov}\\left(\\mathrm{x}_{i}, \\mathrm{x}_{j}\\right)\\)<br></div></div><div><br></div><div>The diagonal elements of the covariance give the variance<br></div>"
                    ],
                    "guid": "Ork>s4!FG>",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the gaussian distribution",
                        "\\(\\mathcal{N}\\left(x ; \\mu, \\sigma^{2}\\right)=\\sqrt{\\frac{1}{2 \\pi \\sigma^{2}}} \\exp \\left(-\\frac{1}{2 \\sigma^{2}}(x-\\mu)^{2}\\right)\\)<div><br></div><div>Two paratmeters&nbsp;\\(\\mu \\in \\mathbb{R}\\) and \\(\\sigma \\in(0, \\infty)\\).</div><div><br></div><div>\\(\\mu\\) gives the coordinate of the central peak<br></div><div>\\(\\sigma\\) controls the width of the peak</div><div><br></div><div>When we need to evaluate the PDF we have to square and invert \\(\\sigma\\).&nbsp;</div><div>A more efficient way to do this is to parametise the guassian with a parameter \\(\\beta \\in(0, \\infty)\\)&nbsp; to control the precision of the distribution.</div><div><img src=\"paste-4358772adc09fae166f662c262063f4594bbba71.jpg\"><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "NX|hNQG!w]",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the central limit theorem?",
                        "<div>The sum of many independent random variables is approximately normally distributed</div>"
                    ],
                    "guid": "L;J.Lkja9c",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the exponential and laplace distributions?&nbsp;",
                        "<div><u><b>Exponential Distribution</b></u></div>In DL we often want to have a probability distribution with a sharp point at x = 0. This is achieved by using the exponential distribution.<div>\\(p(x ; \\lambda)=\\lambda \\mathbf{1}_{x \\geq 0} \\exp (-\\lambda x)\\)<br></div><div><b><br></b></div><div><b>Mean:&nbsp;<i>λ</i><sup>−1</sup>&nbsp;</b></div><div><b>Variance:&nbsp;<i>λ</i><sup>−2</sup></b></div><div><img src=\"325px-Exponential_pdf.svg.png\"><br></div><div><br></div><div>The exponential distribution uses the indicator function&nbsp;\\(\\mathbf{1}_{x \\geq 0}\\) to assign probability zero to all negative values of x.</div><div><br></div><div><u><b>Laplace Distribution</b></u></div><div>Allows us to place a sharp point at an arbitrary point \\(\\mu\\).</div><div><b><br></b></div><div><b>Mean:&nbsp;&nbsp;\\(\\mu\\)</b></div><div><b>Variance \\(2b^{2}\\)</b></div><div><br></div><div><img src=\"325px-Laplace_pdf_mod.svg.png\"><br></div><div><div>\\(\\operatorname{Laplace}(x ; \\mu, \\gamma)=\\frac{1}{2 \\gamma} \\exp \\left(-\\frac{|x-\\mu|}{\\gamma}\\right)\\)<br></div><div><br></div></div>"
                    ],
                    "guid": "/NIWeb/j]",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a latent variable?",
                        "A random variable that we cannot observe directly"
                    ],
                    "guid": "lJ1cA##=Sz",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are structured probabilistic models (/graphical models)?",
                        "Instead of using a single function to represent a probability distribution, we can split a probability distribution in to many factors that we can multiply together. Factorizing can reduce the number of parameters needed to describe the distribution.<div>The factorizations are described as graphs.<br></div><div><br></div><div>Baysian networks (directed acyclic), Markov random fields (undirected)</div><div><br></div><div>Example: the factorization</div><div>\\(P[A,B,C,D] = P[A] \\cdot P[B] \\cdot P[C,D | A,B]\\)</div><div>corresponds to the graph</div><div><img src=\"220px-Graph_model.svg.png\"></div>"
                    ],
                    "guid": "E4Cf_:l}5g",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is Bayes error?",
                        "The error incurred by an oracle making predictions from the true distribution \\(p(\\boldsymbol{x}, y)\\).<div><br></div><div>This error be from errors in the distribution or the mapping from x to y may be inherently stochastic.<div><br></div></div>"
                    ],
                    "guid": "Im^UI?#[<4",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is a point estimator?",
                        "<b>any function of the data</b><div><b><br></b></div><div>\\(\\hat{\\boldsymbol{\\theta}}_{m}=g\\left(\\boldsymbol{x}^{(1)}, \\ldots, \\boldsymbol{x}^{(m)}\\right)\\)<b><br></b></div><div><br></div><div>A <b>good estimator </b>is a function whose output is close to the true underlying&nbsp;\\(\\theta\\) that generated the training data&nbsp;</div><div><br></div><div><br></div>"
                    ],
                    "guid": "gb_}XPKZ??",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is the bias of an estimator?",
                        "\\(\\operatorname{bias}\\left(\\hat{\\boldsymbol{\\theta}}_{m}\\right)=\\mathbb{E}\\left(\\hat{\\boldsymbol{\\theta}}_{m}\\right)-\\boldsymbol{\\theta}\\)<div><br></div><div>the expectation is over the data (seen as samples from a random variable)<br></div><div>\\(\\boldsymbol{\\theta}\\) is the true underlying value of \\(\\boldsymbol{\\theta}\\) used to define the data-generating distribution<br></div><div><br></div><div>An estimator \\(\\hat{\\boldsymbol{\\theta}}_{m}\\) is said to be <b>unbiased</b> if \\(\\operatorname{bias}\\left(\\hat{\\boldsymbol{\\theta}}_{m}\\right)=\\mathbf{0}\\)<br></div><div><br></div><div><b>Asymptotically unbiased&nbsp;</b>\\(\\lim _{m \\rightarrow \\infty} \\operatorname{bias}\\left(\\hat{\\boldsymbol{\\theta}}_{m}\\right)=\\mathbf{0}\\)</div><div><br></div>"
                    ],
                    "guid": "GND2McaWg-",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "how do people interpret maximum likelihood (plain english)?",
                        "<div><b>minimizing the dissimilarity between the empirical distribution and the model distribution</b><b><br></b></div><div><b><br></b></div><div>minimizing the dissimilarity<b> </b>between the empirical distribution ˆp data, deﬁned by the training set and the model distribution, with the <b>degree of dissimilarity</b> between the two</div><div><b>measured by the KL divergence</b>.</div>"
                    ],
                    "guid": "ysI//fdd1!",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe MLE",
                        "<div>Change model parameters \\(\\boldsymbol{\\theta}_{\\mathrm{ML}}\\) to maximize the likelihood of the model given observed data. \\(\\hat{p}_{\\text { data }}\\) and&nbsp;\\(p_{\\text {model}}\\)&nbsp;</div><div><br></div><div>\\(\\boldsymbol{\\theta}_{\\mathrm{ML}}=\\underset{\\boldsymbol{\\theta}}{\\arg \\max } \\mathbb{E}_{\\mathbf{x} \\sim \\hat{p}_{\\text { data }}} \\log p_{\\text { model }}(\\boldsymbol{x} ; \\boldsymbol{\\theta})\\)<br></div><div><br></div><div>Conditional MLE: \\(\\boldsymbol{\\theta}_{\\mathrm{ML}}=\\underset{\\boldsymbol{\\theta}}{\\arg \\max } \\sum_{i=1}^{m} \\log P\\left(\\boldsymbol{y}^{(i)} | \\boldsymbol{x}^{(i)} ; \\boldsymbol{\\theta}\\right)\\)</div><div><br></div><div><u>Detailed</u></div>Consider a set of m examples&nbsp;\\(\\mathbb{X}=\\left\\{\\boldsymbol{x}^{(1)}, \\ldots, \\boldsymbol{x}^{(m)}\\right\\}\\) drawn independently from the true but unknown data-generating distribution&nbsp;\\(p_{\\text { data }}(\\mathbf{x})\\).&nbsp;<div><br></div><div>Let \\(p_{\\bmod \\mathrm{el}}(\\mathbf{x} ; \\boldsymbol{\\theta})\\) be a parametiric family of probability distributions over the same space indexed by&nbsp;\\(\\theta\\).<br></div><div>I.e.&nbsp;\\(p_{\\bmod \\mathrm{el}}(\\mathbf{x} ; \\boldsymbol{\\theta})\\) maps any configuration&nbsp;\\(\\boldsymbol{x}\\) to a real number estimating the true probability&nbsp;\\(p_{\\mathrm{data}}(\\boldsymbol{x})\\).</div><div><br></div><div>The maximum likelihood estimator for&nbsp;&nbsp;\\(\\theta\\) is then defined as&nbsp;</div><div><br></div><div>\\(\\begin{aligned} \\boldsymbol{\\theta}_{\\mathrm{ML}} &amp;=\\underset{\\boldsymbol{\\theta}}{\\arg \\max } p_{\\text { model }}(\\mathbb{X} ; \\boldsymbol{\\theta}) \\\\ &amp;=\\underset{\\boldsymbol{\\theta}}{\\arg \\max } \\prod_{i=1}^{m} p_{\\text { model }}\\left(\\boldsymbol{x}^{(i)} ; \\boldsymbol{\\theta}\\right) \\end{aligned}\\)<br></div><div><br></div><div>Using log likelihood derivative trick we get</div><div><br></div><div>\\(\\boldsymbol{\\theta}_{\\mathrm{ML}}=\\underset{\\boldsymbol{\\theta}}{\\arg \\max } \\sum_{i=1}^{m} \\log p_{\\mathrm{model}}\\left(\\boldsymbol{x}^{(i)} ; \\boldsymbol{\\theta}\\right)\\)<br></div><div><br></div><div>\\(\\boldsymbol{\\theta}_{\\mathrm{ML}}=\\underset{\\boldsymbol{\\theta}}{\\arg \\max } \\mathbb{E}_{\\mathbf{x} \\sim \\hat{p}_{\\text { data }}} \\log p_{\\text { model }}(\\boldsymbol{x} ; \\boldsymbol{\\theta})\\)<br></div><div><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "CHT#[*JQ}p",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How can one make models generalize better without collecting new training data?",
                        "<b>Dataset augmentation</b><div><b><br></b></div><div><img src=\"Screenshot 2019-06-05 at 19.58.41.png\"><b><br></b></div>"
                    ],
                    "guid": "FXFnqem/j)",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the Poisson distribution",
                        "Discrete probability<div><br></div><div><b>Expresses the probability of a given number of events occurring in a fixed interval of time or space.</b></div><div><br></div><div><b>If events occur with a known constant rate and indepdently of the time since last event.</b></div><div><br></div><div>e.g. Number of phone calls received by a call center per hour</div><div><br></div><div>\\(\\lambda\\) is called the event rate, it is the average number of events in an interval</div><div><br></div><div>\\(P(k \\text { events in interval })=e^{-\\lambda} \\frac{\\lambda^{k}}{k !}\\)<br></div><div><br></div><div>Mean:&nbsp;\\(\\lambda\\)</div><div>Variance:&nbsp;\\(\\lambda\\)&nbsp;<br></div><div><br></div><div><img src=\"325px-Poisson_pmf.svg.png\"><br></div>"
                    ],
                    "guid": "HM%qIy1[PB",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why use Monte Carlo Sampling?",
                        "<div>When a sum or an integral cannot be computed exactly, it is often possible to approximate it using Monte Carlo sampling.&nbsp;</div>"
                    ],
                    "guid": "dm/76K{aIR",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is Monte Carlo sampling?",
                        "<div>1) View a sum or integral as an expectation under some distribution</div><div>2)&nbsp;approximate the expectation by a corresponding average</div><div>\\(s=\\int p(\\boldsymbol{x}) f(\\boldsymbol{x}) d \\boldsymbol{x}=E_{p}[f(\\mathbf{x})]\\)<br></div><div><br></div><div>Usually \\(f(x)\\) is easy to compute/measure, but the integral is hard.</div>"
                    ],
                    "guid": "uK_D=wMOW<",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is importance sampling?",
                        "<div>Estimating properties of a distribution using data sampled from a different distribution.</div><div></div><div><br></div><div>In many applications we want to compute µ = E(f(X)) where f(x) is nearly zero outside a region A for which P(X ∈ A) is small. The set A may have small volume, or it may be in the tail of the X distribution. A plain Monte Carlo sample from the distribution of X could fail to have even one point inside the region A.<br></div><div><br></div><div><b><br></b></div><div><b>We do this by sampling from a distribution that overweights the important region, hence the name importance sampling. Having oversampled the important region, we have to adjust our estimate somehow to account for having sampled from this other distribution.</b><br></div>"
                    ],
                    "guid": "v+n_9)Lyy+",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is a stochastic matrix",
                        "A matrix whose columns represents a probability distribution."
                    ],
                    "guid": "x%/)k$R,C1",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Generally how do frequentist and bayesian probability differ?",
                        "Frequentist: probability = expected long run probability of occurrance.<div><br><div>Bayesian: probaiblity = degree of belief. Incorporate priors</div></div>"
                    ],
                    "guid": "n0F=:66mHa",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a random variable?",
                        "possible values are outcomes of a random phenomenon"
                    ],
                    "guid": "Oe8y5]yv?W",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a probability distribution?",
                        "A probablity distribution maps outcomes of a statistical experiment to probabilities of occurrance.<div><br></div><div>It is a summary description of a random phenomenon in terms of event probabilities.</div>"
                    ],
                    "guid": "qpM3)+M-PB",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a probability mass function?",
                        "**discrete values**<div>A probability mass function gives the probability that a discrete random value is exactly equal to some value.</div><div>The sum of the pmf for all possible outcome values must equal 1.</div>"
                    ],
                    "guid": "o?Xj7@phYK",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a probability density function?",
                        "** for continuous variables **<div>PDF maps points in sample space to probability densities. The probability of observing a value in some range is the integral of the PDF over that range.</div><div><br></div>"
                    ],
                    "guid": "f7>g2FZ..)",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a joint probability distribution?",
                        "A joint probability distribution is the probability distribution of 2+ variables."
                    ],
                    "guid": "nj4kP&]F;3",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are the conditions for a function to be a probability mass function?",
                        "Discrete domain, sums to one"
                    ],
                    "guid": "x|tmT`8KsK",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are the conditions for a function to be a probability density function?",
                        "\\( f(x) \\geq 0 \\) for all x<div>\\( \\int_{x} f(x) = 1 \\)</div>"
                    ],
                    "guid": "c<-fci~VL~",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In words, what is a marginal probability?",
                        "Marginal probability is the probability of an event, *not* conditioned on any other event."
                    ],
                    "guid": "ccfc@}9?=-",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the marginal probability of a certain variable in a joint probability function?",
                        "\\( p(x) = \\sum_{y} p(x,y) = \\sum_{y} p(x | y) p(y) \\)"
                    ],
                    "guid": "oQtm9d~KKi",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In words, what is conditional probability?",
                        "Conditional probability is the probability of certain outcome of a random event given that another random event has had a particular outcome."
                    ],
                    "guid": "Nmd63~Z2HE",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do you calculate the conditional probability from a joint probability function?",
                        "\\( p(x|y) = p(x,y) / p(y) \\)"
                    ],
                    "guid": "zf%,4Cm3ty",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the chain rule of conditional probabilities?",
                        "\\( P(A, B) = P(A|B) P(B) \\)"
                    ],
                    "guid": "j}[rEc(>dt",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are the conditions for independence and conditional independence of two random variables?",
                        "Independence:&nbsp;<div>\\( p(x,y) = p(x) p(y) \\)</div><div><br><div>Conditional independence:&nbsp;</div><div>\\( p(x, y|z) = p(x|z) p(y|z)\\)</div></div>"
                    ],
                    "guid": "9dnNt>7uB",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are expectation, variance, and covariance?",
                        "Expectation: mean/first moment.&nbsp;<div>\\( \\mu(X) = E[X] \\)</div><div><br></div><div>Variance:&nbsp;</div><div>\\( \\text{var}(X) = \\sigma^2(X) = E[(X - \\mu)^2]\\)</div><div><br></div><div>Covariance:</div><div>\\( \\text{cov}(X, Y) = E[(X - E[X])(Y-E[Y])] \\)</div>"
                    ],
                    "guid": "Istt_uJ/is",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "When is the covariance of two random variables large? small?",
                        "<div>Covariance:&nbsp;</div><div>\\( \\text{cov}(X, Y) = E[(X - E[X])(Y-E[Y])] \\)</div><div><br></div><div>Cov tends to be large if (X is large when Y is large) and (X is small when Y is small).&nbsp;</div><div><br></div><div>If X is large + negative when Y is large or vise versa (but smalls still go together), then the covariance tends to be large and negative.</div><div><br></div><div>Independence -&gt; covariance=0</div><div>covariance=0 does not imply independence.</div><div><br></div><div><br></div>"
                    ],
                    "guid": "GL4|1zRl9w",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In words, what is the covariance matrix?",
                        "The covariance matrix is the covariance of a vector of random variables."
                    ],
                    "guid": "wZVb_=0?GD",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a Bernoulli distribution? What are the expected mean and variance?",
                        "Bernoulli distributions describe binary random variables (0/1 outcomes).&nbsp;<div><div>Parameterized by \\(k \\in {0,1}\\):&nbsp;</div><div>\\( f(k; p) = p^{k} (1-p)^{1-k} \\)</div><div><br></div><div>Mean: \\( E(X) = \\mu = p \\).<br></div><div>Variance: \\(Var(X) = p(1-p) \\).</div><div><br></div><div><br></div></div>"
                    ],
                    "guid": "l;7r@8o.8[",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a multinoulli distribution?",
                        "discrete random variable that can take one of K values<div>= categorical distribution</div><div>PMF: \\(f(x|p) = \\Pi_{i=1}^{k} p_{i}^{x_{i}} \\)</div>"
                    ],
                    "guid": "lTaJ%4IZ@[",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is PMF of a normal distribution?",
                        "Gaussian distribution<div>\\[ f(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\]</div><div>where \\(E(X)=\\mu\\) and \\(\\text{Var}(X)=\\sigma^2\\)</div>"
                    ],
                    "guid": "n1UuYv_vfd",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why is the normal distribution a go-to choice for a prior over a set of real numbers?",
                        "The Central Limit Theorem tell us that as the sample size tends to infinity, the of the distribution of sample means approaches the normal distribution.&nbsp;<div><br></div><div>A normal distribution is bell shaped so the shape of the distribution of sample means begins to look bell shaped as the sample size increases.</div>"
                    ],
                    "guid": "bS^3zN7>g7",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the Central Limit Theorem?",
                        "when independent random variables are added, their properly normalized sum tends toward a normal distribution (informally a \"bell curve\") even if the original variables themselves are not normally distributed. The theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions."
                    ],
                    "guid": "p3l!bKBo3S",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the exponential distribution?",
                        "The exponential distribution is the probability distribution of the time between events in a poisson process. It is a special case of the gamma distribution.<div><br></div><div>The pdf is \\( f(x; \\lambda) = \\lambda \\exp(-\\lambda x)\\) when \\(x\\geq 0\\),&nbsp; and \\( f(x; \\lambda) = 0 \\) otherwise.</div><div><br></div>"
                    ],
                    "guid": "D@:$iY6n*,",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the Laplace distribution?",
                        "The Laplace distribution (also Gumbel distribution or double exponential distribution) is essentially two exponential distributions glued together back to back, with the mean shifted from zero to \\(\\mu\\).<div><br></div><div>\\[ f(x | \\mu, b) = \\frac{1}{2b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right) \\]</div><div><br></div><div>The difference between two IID exponential random variables is governed by a Laplace distribution, as is a Brownian motion evaluated at an exponentially distributed random time.<br></div>"
                    ],
                    "guid": "E$[~s(2#`x",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the Dirac distribution?",
                        "The Dirac distribution (\"dirac delta function\") is a univariate probability distribution function with all its mass exactly at \\(x=0\\).<div>It is also the zero-variance limit of a zero-centered normal distribution.</div>"
                    ],
                    "guid": "x=>O*91:|",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a mixture of distributions?",
                        "the weighted combination of a bunch of distributions.<div>If all the underlying distributions are continuous, the pdf is a convex combination of the underlying distributions.</div>"
                    ],
                    "guid": "ocI$e,ruL{",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is Bayes's rule?",
                        "\\[ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} \\]"
                    ],
                    "guid": "AlV@#v23p`",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the population mean? Sample mean?",
                        "The population mean (\\(\\mu\\)) is the arithmetic mean of a property for all members of a population<div>The sample mean (\\(\\bar{x}\\)) is the mean of that property for a sample of the population.</div>"
                    ],
                    "guid": "im26$<)`B,",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are population and sample standard deviation?",
                        "Population standard deviation (pop size \\(N\\)):<div>\\( \\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (x_{i} - \\mu)^2} \\)</div><div><br></div><div>(corrected) Sample standard deviation (sample size \\(N\\)):<div>\\( s = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^{N} (x_{i} - \\bar{x})^2} \\)</div></div><div><br></div><div>factor of \\(N-1\\) in \\(s\\) comes from \"Bessel's correction\", which makes for a less biased estimator than \\(N\\) would.</div>"
                    ],
                    "guid": "unt(i|k9,$",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why does population standard deviation have N degrees of freedom while sample s.d. has N-1 dof?",
                        "(\"Bessel's correction\")<div><br></div><div>This correction reduces (but does not eliminate) bias in the sample standard deviation.</div><div><br></div><div>Low-quality justification: one of the data degrees of freedom is eaten by the sample mean estimate, upon which the sample s.d. depends.</div><div>Slightly better: the average distance between samples and the sample mean (zero) will always be greater than the average distance between sampes and the population mean.</div>"
                    ],
                    "guid": "gs~1haN9ln",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the standard error of the mean?",
                        "The standard error of the mean (SEM, \\(\\sigma_{\\bar{x}}\\)) is a standard deviation of a sample mean.<div>For a sample of size \\(n\\) from a population with standard deviation \\(\\sigma\\), it is</div><div>\\(\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}} \\)</div><div><br></div><div>Similarly the standard deviation of a sample mean is&nbsp;</div><div><div>\\(s_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\)</div></div><div><br></div><div>Sample SE is a biased estimator (underestimator) of SE.</div><div><br></div><div>Generally, standard error of a statistic is the s.d. of sample estimates of that statistic.</div>"
                    ],
                    "guid": "pHQ?=F*vv-",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a confidence interval?",
                        "The confidence interval is an estimated plausible range for an unknown parameter.&nbsp;<br>"
                    ],
                    "guid": "Ee4gI@JBUv",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In learning theory, what is bias?",
                        "Bias is the difference between the expected value of estimates of some parameter and the true underlying value of that parameter.<div><br></div><div><div>Formally, if we'd like to estimate a function \\(f(x)\\) using using a sampled supervised training dataset \\(D\\):</div><div>\\[ \\text{Bias}_{D}(\\hat{f}) = E_{D}[\\hat{f}(x; D)] -f(x) \\]</div><div>where the expectation is over choices of the training dataset.<br></div></div>"
                    ],
                    "guid": "LG#Qz6m-6<",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "In learning theory, what is variance (i.e. in \"bias-variance tradeoff\")?",
                        "In this context, \"variance\" refers to variability in parameter estimates (/predictions) among samples.<div><br></div><div>Formally, if we'd like to estimate a function \\(f(x)\\) using using a sampled supervised training dataset \\(D\\):</div><div><div>\\[ \\text{Var}(\\hat{f}) = E_{D} \\left[ ( E_{D}[\\hat{f}] - \\hat{f} )^2 \\right] \\]</div></div><div>where \\(\\hat{f} = \\hat{f} ( x; D)\\) and the expectation is over choices of the training dataset.<br></div>"
                    ],
                    "guid": "y2bFCx@7W%",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the bias-variance tradeoff?",
                        "<div><a href=\"https://www.google.com/imgres?imgurl=https%3A%2F%2Fdjsaunde.files.wordpress.com%2F2017%2F07%2Fbias-variance-tradeoff.png&amp;imgrefurl=https%3A%2F%2Fdjsaunde.wordpress.com%2F2017%2F07%2F17%2Fthe-bias-variance-tradeoff%2F&amp;tbnid=hq3vdIfiIojNsM&amp;vet=12ahUKEwifstXaqLLsAhXyBzQIHbcQAlEQMygDegUIARDEAQ..i&amp;docid=uL9Wk3MBoJI8vM&amp;w=438&amp;h=239&amp;q=bias%20variance%20tradeoff&amp;ved=2ahUKEwifstXaqLLsAhXyBzQIHbcQAlEQMygDegUIARDEAQ\"><img src=\"paste-58824f51988fbb4c7e50e3d47723f0701a94d99c.png\"></a></div><div>In SL, the generalization error that occurs when a model is applied to unseen data can typically be decomposed into bias, variance, and irreducible error. (with an MSE loss function, this is exactly the case)</div><div><br></div><div>Models with high bias underfit/don't model the underlying data well, but can have low variance. Models with high variance tend to overfit to the particular training set.</div><div><br></div><div>Typically, model complexity modulates the balance between bias and variance.&nbsp;</div><a href=\"https://www.google.com/imgres?imgurl=https%3A%2F%2Fdjsaunde.files.wordpress.com%2F2017%2F07%2Fbias-variance-tradeoff.png&amp;imgrefurl=https%3A%2F%2Fdjsaunde.wordpress.com%2F2017%2F07%2F17%2Fthe-bias-variance-tradeoff%2F&amp;tbnid=hq3vdIfiIojNsM&amp;vet=12ahUKEwifstXaqLLsAhXyBzQIHbcQAlEQMygDegUIARDEAQ..i&amp;docid=uL9Wk3MBoJI8vM&amp;w=438&amp;h=239&amp;q=bias%20variance%20tradeoff&amp;ved=2ahUKEwifstXaqLLsAhXyBzQIHbcQAlEQMygDegUIARDEAQ\"><div></div></a>"
                    ],
                    "guid": "FF8G8Q2t>)",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is risk? Empirical risk? Empirical risk minimization?",
                        "<div>In the context of ERM, the risk of a candidate model (hypoethesis) is the expected&nbsp; loss over the true data distribution.<br></div><div>The empirical risk is the expected risk of a hypothesis over the training set/available data; e.g. in SL:</div><div>\\( R_{\\text{emp}(h)} = \\frac{1}{n} \\sum_{i=1}^{n} L(h(x_{i}), y_{i})) \\)</div><div><br></div><div>Empircal risk minimization is the principle that a learning algorithm should choose a hypothesis \\(h \\in H\\) that minimizes the empirical risk:</div><div><div>\\(\\hat{h} = \\text{arg} \\text{min}_{h \\in H} R_{\\text{emp}} (h). \\)</div></div>"
                    ],
                    "guid": "r,P?X&U@.2",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the union bound?",
                        "Union bound:<div>Suppose \\(a\\) and \\(b\\) are independent events, not necessarily independent. Then:</div><div>\\[\\text{Pr}(a\\cup b) \\leq \\text{Pr}(a) + \\text{Pr}(b) \\]</div>"
                    ],
                    "guid": "Oy8UtK&![@",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        },
        {
            "__type__": "Deck",
            "children": [],
            "crowdanki_uuid": "427ae3c4-7f79-11eb-a863-367dda5da221",
            "deck_config_uuid": "427ae6a8-7f79-11eb-a863-367dda5da221",
            "desc": "",
            "dyn": 0,
            "extendNew": 0,
            "extendRev": 0,
            "media_files": [
                "Screenshot 2019-05-21 at 14.59.32.png",
                "Screenshot 2019-05-22 at 22.11.56.png",
                "Screenshot 2019-05-24 at 11.47.41.png",
                "Screenshot 2019-05-24 at 12.56.29.png",
                "Screenshot 2019-05-24 at 15.07.17.png",
                "paste-0933d8af4d621c0e38464bbc1cb24d00cd196777.jpg",
                "paste-1cd7f96f3db143f1d24dcc786023dc87ddf68c6e.jpg",
                "paste-1ef506327df95bca8e670815643f9efbb82d387c.jpg",
                "paste-24b8714174e62452f72eee87c2e5d9eb3dc3dd31.jpg",
                "paste-2e53432da4044572476c6597e897e399c83ee1a5.jpg",
                "paste-4b153aa8b929c6044b21dcd5d19c1ace4b20ebea.jpg",
                "paste-61d50df17db1dbffa2363b27a829cdaaa0b8ff79.jpg",
                "paste-623726d18f65c53fee9457d85b9dcc45d903aed7.jpg",
                "paste-74e893c4b8608fa5678a278d44f85b24cda25c5c.jpg",
                "paste-80be935093bf5a14b649f478decf4066083ff8df.jpg",
                "paste-aaa5908e0e25e981ba8dc85d6cd874f963d9027e.jpg",
                "paste-bcb17488088204e0949f2c1e71494a54d4b8154e.jpg",
                "paste-bd27abe76ca009c1c3fb4a1bb801557cfa45f039.jpg",
                "paste-c047fd8f8b8a35186cc4bd03fe8ad79d8c19c5b1.jpg",
                "paste-c58cd99b5f4817b5414ef7d8f124965a8c643e02.jpg",
                "paste-c62968e806545865e01281fa4a3381f1d7a29c4e.jpg",
                "paste-cf477cc39d11ac2dfaec604081b6453e3f3aa572.jpg",
                "paste-d0fcd7b4c9214b2ad04b1021a12f05f3a593819b.jpg",
                "paste-dbc5f448af2d1e632dc6e9fb87a5b97497ebc278.jpg",
                "paste-e63f467938ae5a3d79d14305b5778f13d8d993ea.jpg",
                "paste-e880780965b752726ed78d2a3723222e39713fd4.jpg",
                "paste-f16e7f0fc918e68ff6b47449acd8e06b60b27336.jpg",
                "paste-fb519994ef159a556f028d7cfd0ede5fe2957647.jpg",
                "pseudotmp11.png"
            ],
            "name": "reinforcement_learning",
            "notes": [
                {
                    "__type__": "Note",
                    "fields": [
                        "What is on policy vs off policy?",
                        "<u><b>On Policy</b></u><div>\"learning on the job whilst following the behavior you’re learning about\"<br></div><div><br></div><div><b>Learn about policy \\(\\pi\\) from experience sampled from \\(\\pi\\)</b><br></div><div><br></div><div>E.g. TD, SARSA</div><div><div><br></div><div><u><b>Off Policy</b></u></div><div>\"learning whilst following someone else’s behavior \"</div><div><br></div><div><b>Learn about policy \\(\\pi\\) from experience sampled from \\(\\mu\\)</b><br></div><div><br></div><div>E.g. Q-Learning, R-Learning</div></div>"
                    ],
                    "guid": "zj!QUkkwN2",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is a policy?",
                        "A policy \\(\\pi\\) is a distribution over actions given states,<br>\\(\\pi(a | s)=\\mathbb{P}\\left[A_{t}=a | S_{t}=s\\right]\\)<div><br></div><div>A policy fully defines the behaviour of an agent</div>"
                    ],
                    "guid": "uwS2+bE34+",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is an action-value function?",
                        "The action-value function \\(q_{\\pi}(s, a)\\) is the expected return starting from state \\(s,\\) taking action \\(a,\\) and then following policy \\(\\pi\\)<br>\\(q_{\\pi}(s, a)=\\mathbb{E}_{\\pi}\\left[G_{t} | S_{t}=s, A_{t}=a\\right]\\)"
                    ],
                    "guid": "z$^iR9PZ.]",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the bellman expectation equation for&nbsp;\\(Q^{\\pi}\\)?",
                        "\\(q_{\\pi}(s, a)=\\mathcal{R}_{s}^{a}+\\gamma \\sum_{s^{\\prime} \\in \\mathcal{S}} \\mathcal{P}_{s s^{\\prime}}^{a} v_{\\pi}\\left(s^{\\prime}\\right)\\)<div><br></div><div>If we start off taking some action from a state, how good is it to take that action and end up in that state.</div><div><br></div><div><img src=\"paste-1ef506327df95bca8e670815643f9efbb82d387c.jpg\"><br></div><div><br></div>"
                    ],
                    "guid": "G#o<rKm`He",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the optimal state-value function&nbsp;\\(v_{*}(s)\\)?",
                        "The maximum value function over all policies,&nbsp;<div><br></div><div>\\(v_{*}(s)=\\max _{\\pi} v_{\\pi}(s)\\)</div><div><br></div><div>Specifies the best possible peformance in the MDP<br><div><br></div></div>"
                    ],
                    "guid": "xewsSEK9RG",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the optimal action-value function&nbsp;\\(q_{*}(s, a)\\)?",
                        "is the maximum action-value function over all policies<div><br></div><div>\\(q_{*}(s, a)=\\max _{\\pi} q_{\\pi}(s, a)\\)</div>"
                    ],
                    "guid": "c1vk([1f6@",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is an optimal policy?",
                        "An optimal policy \\(\\pi_{*}\\) that is better than or equal to all other policies, \\(\\pi_{*} \\geq \\pi, \\forall \\pi\\)"
                    ],
                    "guid": "E`Dv9N!!D/",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the optimal policy theorem for MDPs?",
                        "There exists an optimal policy<div><br></div><div>All optimal policies achieve optimal state and action value functions.</div>"
                    ],
                    "guid": "bn_|Qtd[&%",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do you find an optimal policy ?",
                        "An optimal policy can be found by maximising over \\(q_{*}(s, a)\\)<div><br></div><div>Every MDP has a deterministic optimal policy.<br></div><div><br></div><div>If we know \\(q_*(s, a)\\), we immediately have the optimal policy.<br></div>"
                    ],
                    "guid": "mwC{hYWB!C",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the bellman optimality equation for \\(v_*(s)\\)?",
                        "<div>\\(v_{*}(s)=\\max _{a} q_{*}(s, a)\\)<br></div><div><br></div><div>Value of the state is given by picking the maximum /best action you can take from that state.</div><div><br></div><div><img src=\"paste-f16e7f0fc918e68ff6b47449acd8e06b60b27336.jpg\"><br></div>"
                    ],
                    "guid": "IIuL@E)pX|",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the bellman optimality equation for \\(q_*(s, a)\\)?",
                        "<div>\\(q_{*}(s, a)=\\mathcal{R}_{s}^{a}+\\gamma \\sum_{s^{\\prime} \\in \\mathcal{S}} \\mathcal{P}_{s s^{\\prime}}^{a} v_{*}\\left(s^{\\prime}\\right)\\)<br></div><div><br></div><div>Do not get to pick where the wind blows us so we take an average</div><div><br></div><div><img src=\"Screenshot 2019-05-21 at 14.59.32.png\"><br></div>"
                    ],
                    "guid": "FG9Fa<V>oO",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the planning for prediction problem?",
                        "Input: MDP and policy \\(\\pi\\)<div><br></div><div>Output: Value function \\(V_{\\pi}\\)</div>"
                    ],
                    "guid": "o0!S0YM{;7",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the planning for control problem",
                        "Input: MDP<div><br></div><div>Output: Optimal value function \\(v_{*}\\) and optimal policy \\(\\pi_{*}\\)</div>"
                    ],
                    "guid": "HX?v#:Vk.f",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe Policy Evaluation",
                        "<u>Problem:</u> Evaluate a given policy \\(\\pi\\)<div><u>Solution:</u> Iterative application of the bellman expectation backup</div><div>\\(v_{1} \\rightarrow v_{2} \\rightarrow \\ldots \\rightarrow v_{\\pi}\\)<br></div><div><br></div><div><br></div><div><u>Procedure:</u></div><div>At each iteration k + 1&nbsp;</div><div>For all states \\(s \\in \\mathcal{S}\\)</div><div>Update&nbsp;\\(v_{k+1}(s)\\) from&nbsp;\\(v_{k}\\left(s^{\\prime}\\right)\\)</div><div><br></div><div>where \\(s^{\\prime}\\) is a successor state of \\(s\\)</div><div><br></div><div><br></div><div>Start off with an initial arbitrary vector, value of all states in MDP. Do 1 step look ahead using Bellman Exp Eq. Figure out new value function. Eventually we get the true value function.</div><div><br></div><div>\\(\\begin{aligned} v_{k+1}(s) &amp;=\\sum_{a \\in \\mathcal{A}} \\pi(a | s)\\left(\\mathcal{R}_{s}^{a}+\\gamma \\sum_{s^{\\prime} \\in \\mathcal{S}} \\mathcal{P}_{s s^{\\prime}}^{a} v_{k}\\left(s^{\\prime}\\right)\\right) \\\\ \\mathbf{v}^{k+1} &amp;=\\mathcal{R}^{\\pi}+\\gamma \\mathcal{P}^{\\pi} \\mathbf{v}^{k} \\end{aligned}\\)<br></div><div><br></div><div><br></div><div><br></div><div><img src=\"paste-24b8714174e62452f72eee87c2e5d9eb3dc3dd31.jpg\"><br></div>"
                    ],
                    "guid": "gPF-$.v5M6",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "How do you improve a policy?",
                        "Given a policy \\(\\pi\\),&nbsp;<div><br></div><div><b>Evaluate </b>policy&nbsp;&nbsp;\\(\\pi\\),&nbsp; Using \\(v_{\\pi}(s)\\)</div><div><br></div><div><b>Improve </b>the policy by acting greedily with respect to&nbsp;&nbsp;\\(v_{\\pi}\\),</div><div><br></div><div>&nbsp; &nbsp; &nbsp;\\(\\pi^{\\prime}=\\operatorname{greedy} \\left(v_{\\pi}\\right)\\)</div><div><br></div><div><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "j4Y6ifIt)3",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe Policy Iteration",
                        "<img src=\"paste-74e893c4b8608fa5678a278d44f85b24cda25c5c.jpg\">"
                    ],
                    "guid": "vIC]09}LUz",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Synchronous Dynamic Programming Algorithms",
                        "\\(\\begin{array}{|c|c|c|}\\hline \\text { Problem } &amp; {\\text { Bellman Equation }} &amp; {\\text { Algorithm }} \\\\ \\hline \\text { Prediction } &amp; {\\text { Bellman Expectation Equation }} &amp; {\\text { Iterative }} \\\\ \\hline \\text { Control } &amp; {\\text { Bellman Expectation Equation + Greedy policy improvement }} &amp; {\\text { Policy Evaluation }} \\\\ \\hline \\text { Control } &amp; {\\text { Bellman Optimality Equation }} &amp; {\\text { Value lteration }} \\\\ \\hline\\end{array}\\)<div><br></div><div>Algorithms are based on state value function</div><div>Complexity is&nbsp; is \\(O(mn^2)\\), m actions n states</div><div><br></div><div>If applied to action value the complexity is \\(O(m^2n^2)\\)</div>"
                    ],
                    "guid": "CmI1rFn=}U",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is model-free prediction?",
                        "Estimate the value function of an unknown MDP."
                    ],
                    "guid": "vM~V/qlak)",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is model-free control?",
                        "Optimise the value function of an unknown MDP."
                    ],
                    "guid": "yD9QKLpA4A",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what are the features of MC reinforcement learning?",
                        "Learn directly from episodes of experience<div>Model free</div><div>Learns from complete episodes</div><div>idea : value = mean return&nbsp;</div><div><br></div><div>Caveat: Can only apply MC to episodic MDPs - All episodes must terminate</div>"
                    ],
                    "guid": "bCge8ugx?<",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe Monte Carlo Policy Evaluation problem set up",
                        "<b style=\"text-decoration-line: underline;\">Goal:</b>&nbsp;learn \\(v_{\\pi}\\) from episodes of experience under policy \\(\\pi\\)<div><br></div><div>\\(S_{1}, A_{1}, R_{2}, \\dots, S_{k} \\sim \\pi\\)<br></div><div><br></div><div>Monte-Carlo policy evaluation uses <i>empirical mean return </i>instead of <i>expected return</i>&nbsp;to get the value at a state given policy \\(\\pi\\)&nbsp;</div><div><br></div>"
                    ],
                    "guid": "f).BhvWYeJ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe First-Visit Monte-Carlo Policy Evaluation",
                        "<div><b>average returns only for first time s is visited in an episode</b><br></div><div><br></div>To evaluate state <i>s, a</i>t the <b>first time-step t,</b> that state <i>s </i>is visited in an episode,<div><br></div><div>Increment counter,&nbsp;\\(N(s) \\leftarrow N(s)+1\\)</div><div>Increment total return,&nbsp;\\(S(s) \\leftarrow S(s)+G_{t}\\)</div><div>Value is estimated by mean return,&nbsp;\\(V(s)=S(s) / N(s)\\)</div><div><br></div><div>By law of large numbers,&nbsp;\\(V(s) \\rightarrow v_{\\pi}(s)\\) as \\(N(s) \\rightarrow \\infty\\)</div><div><br></div><div><img src=\"paste-fb519994ef159a556f028d7cfd0ede5fe2957647.jpg\"><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "N$47cx[jnf",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe every-visit MC Policy Evaluation",
                        "To evaluate state&nbsp;<i>s</i><div><i><br></i></div><div>At the&nbsp;<b>every time-step t,</b>&nbsp;that state&nbsp;<i>s&nbsp;</i>is visited in an episode,</div><div><br></div><div>Increment counter,&nbsp;\\(N(s) \\leftarrow N(s)+1\\)</div><div>Increment total return,&nbsp;\\(S(s) \\leftarrow S(s)+G_{t}\\)</div><div>Value is estimated by mean return,&nbsp;\\(V(s)=S(s) / N(s)\\)</div><div><br></div><div>By law of large numbers,&nbsp;\\(V(s) \\rightarrow v_{\\pi}(s)\\) as \\(N(s) \\rightarrow \\infty\\)</div><br>"
                    ],
                    "guid": "Biql^Jl6^p",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe incremental Monte-Carlo updates",
                        "Update V(s) incrementally after episode&nbsp;\\(S_{1}, A_{1}, R_{2}, \\dots, S_{T}\\)<div><br></div><div>For each state \\(S_{t}\\) with return \\(G_{t}\\),<br></div><div><br></div><div>\\(N\\left(S_{t}\\right) \\leftarrow N\\left(S_{t}\\right)+1\\)<br></div><div><br></div><div><br></div><div>\\(V\\left(S_{t}\\right) \\leftarrow V\\left(S_{t}\\right)+\\alpha\\left(G_{t}-V\\left(S_{t}\\right)\\right)\\)</div><div>In non-stationary problems it may be useful to track only a running mean (forget old episodes) hence the change to the above equation.</div><div><br></div><div><br></div><div><img src=\"paste-623726d18f65c53fee9457d85b9dcc45d903aed7.jpg\"><br></div><div><br></div><div><img src=\"paste-d0fcd7b4c9214b2ad04b1021a12f05f3a593819b.jpg\"><br></div>"
                    ],
                    "guid": "r.n/v~IcPQ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what are the properties of Temporal Difference Learning",
                        "Learn directly from episodes of experience<div>Model free</div><div>Learns from <b>incomplete epsiodes </b>by <b>bootstrapping</b></div><div>TD <b>updates guess towards a guess</b></div>"
                    ],
                    "guid": "dNu{q;6xpZ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the TD(0)",
                        "Goal: learn \\(v_{\\pi}\\) online from experience under policy \\(\\pi\\)<div><br></div><div>Update value \\(V\\left(S_{t}\\right)\\) toward estimated return \\(R_{t+1}+\\gamma V\\left(S_{t+1}\\right)\\)<br>\\(V\\left(S_{t}\\right) \\leftarrow V\\left(S_{t}\\right)+\\alpha\\left(R_{t+1}+\\gamma V\\left(S_{t+1}\\right)-V\\left(S_{t}\\right)\\right)\\)<br></div><div><br></div><div>\\(R_{t+1}+\\gamma V\\left(S_{t+1}\\right)\\) is called the \\(T D\\) target<br>\\(\\delta_{t}=R_{t+1}+\\gamma V\\left(S_{t+1}\\right)-V\\left(S_{t}\\right)\\) is called the \\(T D\\) error<br></div>"
                    ],
                    "guid": "P#xK|bU~HG",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Advantages and Disadvantages of MC vs TD",
                        "<div>TD | MC</div><div>-|-</div><div>Learn each step | Learn only after episode is complete</div><div>Continual learning | Episodic learning</div><div>Biased | Unbiased</div><div>Low variance | High variance<br></div>"
                    ],
                    "guid": "w(l9~^<SVK",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the bias/variance tradeoff for TD and MC policy evaluation",
                        "MC uses full return,&nbsp;\\(G_{t}=R_{t+1}+\\gamma R_{t+2}+\\ldots+\\gamma^{T-1} R_{T}\\) which is an<b> unbiased estimate</b> of&nbsp;\\(v_{\\pi}\\left(S_{t}\\right)\\)<div><br></div><div>True TD target&nbsp;\\(R_{t+1}+\\gamma V\\left(S_{t+1}\\right)\\) is a <b>biased estimate&nbsp;</b>of&nbsp;\\(v_{\\pi}\\left(S_{t}\\right)\\)</div><div>&nbsp; &nbsp; <u><b>TD target</b> is a much<b> lower variance</b> than the return</u>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; MC Return depends on <b>many random </b>actions, transitions, rewards</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TD target depends on <b>one random</b> action, transition, reward</div><div><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "Q6NVYs;gDF",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe properties of MC and TD relating to bias and variance",
                        "<div>MC has high variance, zero bias</div><div>&nbsp; &nbsp; Good convergence properties</div><div>&nbsp; &nbsp; Not very sensitive to initial value</div><div><br></div><div>TD has low variance, some bias</div><div>&nbsp; &nbsp; Usually more efficient then MC</div><div>&nbsp; &nbsp; TD(0) converges to&nbsp;\\(v_{\\pi}(s)\\)</div><div>&nbsp; &nbsp; More sensitive to initial value</div>"
                    ],
                    "guid": "JoEMRrUQX+",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what property does TD exploit that MC does not ?",
                        "TD exploits the Markov property, usually more efficient in Markov environments<div><br></div><div>MC does not exploit Markov property, usually more effective in non-Markov environments<br><div><br></div><div><br></div></div>"
                    ],
                    "guid": "uOw%-usPL`",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is Bootstrapping and Sampling in terms of RL?",
                        "<b style=\"text-decoration-line: underline;\">Bootstrapping:</b>&nbsp;Update involves an estimate<div><br><div>MC does not bootstrap</div><div>DP bootstraps</div><div>TD bootstraps</div><div><br></div><div><u style=\"font-weight: bold;\">Sampling:</u>&nbsp;Update samples an expectation</div></div><div><br></div><div>MC samples</div><div>DP does <b>does not</b>&nbsp;sample</div><div>TD samples</div>"
                    ],
                    "guid": "I`ma!}j?p7",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the unified view of RL",
                        "<img src=\"paste-1cd7f96f3db143f1d24dcc786023dc87ddf68c6e.jpg\">"
                    ],
                    "guid": "GjSaL8.IG2",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Define n-Step prediction",
                        "<img src=\"paste-bd27abe76ca009c1c3fb4a1bb801557cfa45f039.jpg\">"
                    ],
                    "guid": "v:rt}.Uw^/",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Define n-step return and n-step temporal-difference learning",
                        "<div><u><b>n-step return</b></u><br></div><div><u><b><br></b></u></div><div>\\(G_{t}^{(n)}=R_{t+1}+\\gamma R_{t+2}+\\ldots+\\gamma^{n-1} R_{t+n}+\\gamma^{n} V\\left(S_{t+n}\\right)\\)<u><b><br></b></u></div><div><br></div><div><u><b>n-step temporal-difference learning</b></u></div><div><u><b><br></b></u></div><div>\\(V\\left(S_{t}\\right) \\leftarrow V\\left(S_{t}\\right)+\\alpha\\left(G_{t}^{(n)}-V\\left(S_{t}\\right)\\right)\\)<u><b><br></b></u></div>"
                    ],
                    "guid": "f0Nxj*g4gc",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe TD(\\(\\lambda\\)",
                        "<div>Lambda return averages multiple n step returns</div><img src=\"paste-aaa5908e0e25e981ba8dc85d6cd874f963d9027e.jpg\">"
                    ],
                    "guid": "NH!5pM_$9V",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe Forward View TD(\\(\\lambda\\))",
                        "<div>Update value function towards the \\(\\lambda\\) return<br></div><div>Forward-view looks into the future to compute \\(G_{t}^{\\lambda}\\)<br></div><div>Like MC, can only be computed from complete episodes</div><img src=\"paste-e880780965b752726ed78d2a3723222e39713fd4.jpg\"><div><br></div>"
                    ],
                    "guid": "FE,~sd+^.F",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe Backward View TD(\\(\\lambda)\\)",
                        "<div><u><b>Procedure</b></u></div><div>Keep an eligibility trace for every state s<br></div><div>Update value V(s) for every state s, in proportion to TD-error δt and eligibility trace Et(s)</div><div><br></div><div><img src=\"pseudotmp11.png\"><br></div><div><br></div><div>\\(\\begin{aligned} \\delta_{t} &amp;=R_{t+1}+\\gamma V\\left(S_{t+1}\\right)-V\\left(S_{t}\\right) \\\\ V(s) &amp; \\leftarrow V(s)+\\alpha \\delta_{t} E_{t}(s) \\end{aligned}\\)<br></div><div><br></div><div><br></div><div><img src=\"Screenshot 2019-05-22 at 22.11.56.png\"><br></div><div><br></div><div><br></div><div>Frequency heuristic: assign credit to most frequent states<br>Recency heuristic: assign credit to most recent states<br>Eligibility traces combine both heuristics<br></div><div><br></div><div><br></div><div><img src=\"paste-e63f467938ae5a3d79d14305b5778f13d8d993ea.jpg\"><br></div><div>\\(E_{0}(s)=0\\)<br>\\(E_{t}(s)=\\gamma \\lambda E_{t-1}(s)+\\mathbf{1}\\left(S_{t}=s\\right)\\)<br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "yAS0g@$`TG",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is model free control ?",
                        "Work out optimal policy and value function without knowing an MDP"
                    ],
                    "guid": "hr+yWf0(W[",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why is greedy action selection bad?",
                        "<div>Greedy action selection causes you to get stuck.&nbsp;</div><div>Bad for exploration.&nbsp;</div><div><br></div><div><img src=\"paste-dbc5f448af2d1e632dc6e9fb87a5b97497ebc278.jpg\"><br></div>"
                    ],
                    "guid": "Bt%#rV^K%I",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "descibe epsilon Greedy Exploration",
                        "<div>Simplest idea for ensuring continual exploration<br></div><div><br></div><div>All m actions are tried with nonzero probability. &nbsp;</div><div><br></div> <div>Probability epsilon choose random action. probabiltiy 1-epsilon for greedy.</div><div><br></div><div>Basically like, flip a coin if its tails you take a random action if it’s heads you take argmax.</div><div><br></div><div>\\(\\pi(a | s)=\\left\\{\\begin{array}{ll}{\\epsilon / m+1-\\epsilon} &amp; {\\text { if } a^{*}=\\underset{a \\in \\mathcal{A}}{\\operatorname{argmax}} Q(s, a)} \\\\ {\\epsilon / m} &amp; {\\text { otherwise }}\\end{array}\\right.\\)<br></div>"
                    ],
                    "guid": "vKD,f~Q[8",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe Monte Carlo Control",
                        "<div>Every episode,</div><div><br></div><div><u>MC Policy evaluation</u>:</div><div><div>Record trajectory of agent update q values of visited states at the end of the episode.&nbsp; \\(Q \\approx q_{\\pi}\\)</div></div><div><br></div><div><u>Policy Improvement</u></div><div>For each s, choose an action by \\(\\epsilon\\)-greedy policy improvement</div><div><div>Use new and updated state-action value function to improve policy&nbsp;&nbsp;</div></div><div><br></div><div><img src=\"Screenshot 2019-05-24 at 11.47.41.png\"><br></div>"
                    ],
                    "guid": "D{9{*BMO5k",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Define Greedy In The Limit with Infinite Exploration (GLIE)",
                        "All state action pairs are explored infinitely many times<div><br></div><div>\\(\\lim _{k \\rightarrow \\infty} N_{k}(s, a)=\\infty\\)<br></div><div><br></div><div>The policy converges on a greedy policy</div><div><br></div><div>\\(\\lim _{k \\rightarrow \\infty} \\pi_{k}(a | s)=\\mathbf{1}\\left(a=\\underset{a^{\\prime} \\in \\mathcal{A}}{\\operatorname{argmax}} Q_{k}\\left(s, a^{\\prime}\\right)\\right)\\)<br></div><div><br></div><div>Example.</div><div>\\(\\epsilon\\) -greedy is GLIE if \\(\\epsilon\\) reduces to zero at \\(\\epsilon_{k}=\\frac{1}{k}\\)<br></div>"
                    ],
                    "guid": "p`pDdbtTJx",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe GLIE MC Control",
                        "<div>&nbsp; Sample \\(k\\) th episode using \\(\\pi :\\left\\{S_{1}, A_{1}, R_{2}, \\dots, S_{T}\\right\\} \\sim \\pi\\)</div><div><br></div><div>For each state \\(S_{t}\\) and action \\(A_{t}\\) in the episode,<br></div><div><br></div><div>\\(N\\left(S_{t}, A_{t}\\right) \\leftarrow N\\left(S_{t}, A_{t}\\right)+1\\)<br>\\(Q\\left(S_{t}, A_{t}\\right) \\leftarrow Q\\left(S_{t}, A_{t}\\right)+\\frac{1}{N\\left(S_{t}, A_{t}\\right)}\\left(G_{t}-Q\\left(S_{t}, A_{t}\\right)\\right)\\)<br></div><div><br></div><div><br></div><div>Improve policy based on new action-value</div><div><br></div><div>\\(\\epsilon \\leftarrow 1 / k\\)<br>\\(\\pi \\leftarrow \\epsilon-\\operatorname{greedy}(Q)\\)<br></div><div><br></div><div>Policy is changing over time we are taking returns from better and better policies into account&nbsp;</div><div><br></div><div><b>This converges to the optimal action-value function</b></div><div><br></div>"
                    ],
                    "guid": "Ne#kKlj(!T",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is the action-value function update with SARSA?",
                        "\\(Q(S, A) \\leftarrow Q(S, A)+\\alpha\\left(R+\\gamma Q\\left(S^{\\prime}, A^{\\prime}\\right)-Q(S, A)\\right)\\)<div><br></div><div><br></div><div><img src=\"paste-2e53432da4044572476c6597e897e399c83ee1a5.jpg\"><br></div>"
                    ],
                    "guid": "hl>~L0pkjG",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe on-policy control with SARSA",
                        "<b>Every time-step,</b><div>Policy evaluation: SARSA,&nbsp;\\(Q \\approx q_{\\pi}\\)</div><div>Policy improvement:&nbsp;\\(\\epsilon\\) -greedy policy improvement</div><div><br></div><div><br><div><br></div></div>"
                    ],
                    "guid": "iH72yIDB+T",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is the SARSA algorithm for on-policy control?",
                        "<img src=\"paste-0933d8af4d621c0e38464bbc1cb24d00cd196777.jpg\">"
                    ],
                    "guid": "y=F|+]&O~N",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe n-Step SARSA",
                        "\\(n\\) -step Q-return<div><br></div><div>\\(q_{t}^{(n)}=R_{t+1}+\\gamma R_{t+2}+\\ldots+\\gamma^{n-1} R_{t+n}+\\gamma^{n} Q\\left(S_{t+n}\\right)\\)<br></div><div><br></div><div>\\(n\\) -step Sarsa updates \\(Q(s, a)\\) towards the \\(n\\) -step \\(Q\\) -return<br></div><div><br></div><div>\\(Q\\left(S_{t}, A_{t}\\right) \\leftarrow Q\\left(S_{t}, A_{t}\\right)+\\alpha\\left(q_{t}^{(n)}-Q\\left(S_{t}, A_{t}\\right)\\right)\\)<br></div>"
                    ],
                    "guid": "qj.w5y@Mar",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe Forward View Sarsa(\\(\\lambda\\))",
                        "The \\(q^{\\lambda}\\) return combines all \\(n\\) -step Q-returns \\(q_{t}^{(n)}\\)<div><br></div><div>Using weight \\((1-\\lambda) \\lambda^{n-1}\\)<br></div><div><br></div><div>\\(q_{t}^{\\lambda}=(1-\\lambda) \\sum_{n=1}^{\\infty} \\lambda^{n-1} q_{t}^{(n)}\\)<br></div><div><br></div><div>\\(Q\\left(S_{t}, A_{t}\\right) \\leftarrow Q\\left(S_{t}, A_{t}\\right)+\\alpha\\left(q_{t}^{\\lambda}-Q\\left(S_{t}, A_{t}\\right)\\right)\\)<br></div><div><br></div><div><img src=\"paste-4b153aa8b929c6044b21dcd5d19c1ace4b20ebea.jpg\"><br></div>"
                    ],
                    "guid": "L~NJ_)D+8D",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe the SARSA(\\(\\lambda\\)) Algorithm",
                        "<img src=\"Screenshot 2019-05-24 at 12.56.29.png\">"
                    ],
                    "guid": "wzJORrQuCv",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "SARSA(\\(\\lambda\\)) Gridworld Example",
                        "<img src=\"paste-c58cd99b5f4817b5414ef7d8f124965a8c643e02.jpg\">"
                    ],
                    "guid": "OR8+]wV?gb",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Why is off-policy learning important?",
                        "Learn from observing humans or other agents<div><br></div><div>Re-use experience generated from old policies \\(\\pi_{1}, \\pi_{2}, \\dots, \\pi_{t-1}\\) (used for the atari games, may have learned something useful in prior policy for another game)</div><div><br></div><div>Learn about optimal policy while following exploratory policy<br></div><div><br></div><div>Learn about multiple policies while following one policy<br></div>"
                    ],
                    "guid": "L;~6%2sK1[",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Importance Sampling for Off-Policy Monte Carlo",
                        "Use returns generated from&nbsp;\\(\\mu\\) to evaluate \\(\\pi\\)<div><br></div><div>Weight return&nbsp;\\(G_{t}\\) according to similarity between policies</div><div><br></div><div>Multiply importance sampling corrections along whole episode</div><div><br></div><div>\\(G_{t}^{\\pi / \\mu}=\\frac{\\pi\\left(A_{t} | S_{t}\\right)}{\\mu\\left(A_{t} | S_{t}\\right)} \\frac{\\pi\\left(A_{t+1} | S_{t+1}\\right)}{\\mu\\left(A_{t+1} | S_{t+1}\\right)} \\dots \\frac{\\pi\\left(A_{T} | S_{T}\\right)}{\\mu\\left(A_{T} | S_{T}\\right)} G_{t}\\)<br></div><div><br></div><div>Update value toward corrected return</div><div><br></div><div>\\(V\\left(S_{t}\\right) \\leftarrow V\\left(S_{t}\\right)+\\alpha\\left(G_{t}^{\\pi / \\mu}-V\\left(S_{t}\\right)\\right)\\)<br></div><div><br></div><div>Cannot use if \\(\\mu\\) is zero when \\(\\pi\\) is non-zero<br></div><div><br></div><div>Because it uses&nbsp;\\(G_{t}\\)&nbsp; you have to wait until the end to update&nbsp;</div><div><br></div><div>Can dramatically increase variance</div><div><br></div>"
                    ],
                    "guid": "iJt(ds38B1",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Importance Sampling for Off-Policy TD",
                        "Use TD targets generated from \\(\\mu\\) to evaluate \\(\\pi\\)<div><br></div><div>Weight TD target \\(R+\\gamma V\\left(S^{\\prime}\\right)\\) by importance sampling<br></div><div><br></div><div>Only need a single importance sampling correction</div><div><br></div><div>\\(\\begin{aligned} V\\left(S_{t}\\right) &amp; \\leftarrow V\\left(S_{t}\\right)+\\\\ &amp; \\alpha\\left(\\frac{\\pi\\left(A_{t} | S_{t}\\right)}{\\mu\\left(A_{t} | S_{t}\\right)}\\left(R_{t+1}+\\gamma V\\left(S_{t+1}\\right)\\right)-V\\left(S_{t}\\right)\\right) \\end{aligned}\\)</div><div><br></div><div>Much lower variance than Monte-Carlo importance sampling<br></div><div>Policies only need to be similar over a single step<br></div>"
                    ],
                    "guid": "PF6jdlv3?p",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe some properties of Q-Learning",
                        "No importance sampling&nbsp;<div><br></div><div>Next action is chosen using behaviour policy \\(A_{t+1} \\sim \\mu\\left(\\cdot | S_{t}\\right)\\)<br></div><div><br></div><div>But we consider alternative successor action \\(A^{\\prime} \\sim \\pi\\left(\\cdot | S_{t}\\right)\\)<br></div><div><br></div><div>And update Q(St , At) towards value of alternative action<br></div><div><br></div><div>\\(Q\\left(S_{t}, A_{t}\\right) \\leftarrow Q\\left(S_{t}, A_{t}\\right)+\\alpha\\left(R_{t+1}+\\gamma Q\\left(S_{t+1}, A^{\\prime}\\right)-Q\\left(S_{t}, A_{t}\\right)\\right)\\)<br></div>"
                    ],
                    "guid": "JV?x}<Dy,=",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "why do we use value function approximation?",
                        "Allows us to scale up RL algorithms to work in large state spaces<div><br></div><div><u>Problem</u>:</div><div>Large MDPs have too many states and or actions to store in memory.</div><div>So we can't just store information such as the value function in a table.</div><div>Too slow to learn the value even if you can store the information.</div><div><br></div><div><u>Solution</u>:</div><div>So instead we estimate the value function using function approximation.</div><div><br></div><div><b>Generalise from seen states to unseen states</b></div><div><br></div><div>\\(\\begin{aligned} \\hat{v}(s, \\mathbf{w}) &amp; \\approx v_{\\pi}(s) \\\\ \\text { or } \\hat{q}(s, a, \\mathbf{w}) &amp; \\approx q_{\\pi}(s, a) \\end{aligned}\\)<br></div><div><br></div><div>Update parameter w using MC or TD learning.</div>"
                    ],
                    "guid": "D`$ycQ[L]f",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe&nbsp;\\(\\hat{V}(\\mathbf{s}, \\mathbf{w})\\) function approximation",
                        "<div>It gives us the value function at query state s. ie. how good it is to be in state s.</div><div><br></div><div>The parameter w, is the internal function that is learned by the function approximator.&nbsp;</div><img src=\"Screenshot 2019-05-24 at 15.07.17.png\">"
                    ],
                    "guid": "gIIgxb.h*r",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe action-in action-value function approximation",
                        "<div>I'm in state s, and I am considering action a, how good will it be to take a, in state s?</div><div><br></div><div><br></div><div><br></div><div>\\(\\hat{\\mathrm{q}}(\\mathrm{s}, \\mathrm{a}, \\mathrm{w})\\)<br></div><div><br></div><img src=\"paste-c047fd8f8b8a35186cc4bd03fe8ad79d8c19c5b1.jpg\">"
                    ],
                    "guid": "bCQ8p0Y{]r",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe action-out action-value function approximation",
                        "<div>I'm in state s, what is the action-value of all the actions I can take?</div><div><br></div><div>So in a single forward pass it returns the value of all the possible actions. Used in atari.&nbsp;</div><img src=\"paste-bcb17488088204e0949f2c1e71494a54d4b8154e.jpg\">"
                    ],
                    "guid": "G<7bkPv|80",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe incremental prediction algorithms",
                        "Do not use/have oracle/true value function&nbsp;\\(v_{\\pi}(s)\\) given by supervisor<div><br></div><div>No supervisor in RL only rewards, so we substitute a target for \\(v_{\\pi}(s)\\)&nbsp;</div><div><br></div><div><u><b>For MC</b></u></div><div>The target is the return&nbsp;\\(G_{t}\\)</div><div>\\(\\Delta \\mathbf{w}=\\alpha\\left(G_{t}-\\hat{v}\\left(S_{t}, \\mathbf{w}\\right)\\right) \\nabla_{\\mathbf{w}} \\hat{v}\\left(S_{t}, \\mathbf{w}\\right)\\)<br></div><div><br></div><div><u><b>For TD(0)</b></u></div><div>The target is the TD Target&nbsp;\\(R_{t+1}+\\gamma \\hat{v}\\left(S_{t+1}, \\mathbf{w}\\right)\\)</div><div>\\(\\Delta \\mathbf{w}=\\alpha\\left(R_{t+1}+\\gamma \\hat{v}\\left(S_{t+1}, \\mathbf{w}\\right)-\\hat{v}\\left(S_{t}, \\mathbf{w}\\right)\\right) \\nabla_{\\mathbf{w}} \\hat{v}\\left(S_{t}, \\mathbf{w}\\right)\\)<br></div><div><br></div><div><u><b>For TD(\\(\\lambda\\)</b></u></div><div>The targe return is&nbsp;\\(\\lambda\\) -return \\(G_{t}^{\\lambda}\\)</div><div><br></div><div>\\(\\Delta \\mathbf{w}=\\alpha\\left(G_{t}^{\\lambda}-\\hat{v}\\left(S_{t}, \\mathbf{w}\\right)\\right) \\nabla_{\\mathbf{w}} \\hat{v}\\left(S_{t}, \\mathbf{w}\\right)\\)<br></div><div><br></div>"
                    ],
                    "guid": "nU]r/?~a~g",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "Describe control with action-value function approximation",
                        "Policy evaluation: Approximate policy evaluation, \\(\\hat{q}(\\cdot,, \\mathbf{w}) \\approx q_{\\pi}\\)<br>Policy improvement: \\(\\epsilon\\) -greedy policy improvement<div><br></div><div><img src=\"paste-80be935093bf5a14b649f478decf4066083ff8df.jpg\"><br></div>"
                    ],
                    "guid": "GFzQsA|B0>",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What is action-value function approximation?",
                        "Approximate the action-value function using a function approximator&nbsp;<div><br></div><div>\\(\\hat{q}(S, A, \\mathbf{w}) \\approx q_{\\pi}(S, A)\\)<br></div><div><br></div><div>Minimise mean-squared error between approximate action-value fn&nbsp;\\(\\hat{q}(S, A, \\mathbf{w})\\) and true action value fn&nbsp;\\(q_{\\pi}(S, A)\\)<br></div><div><br></div><div>\\(J(\\mathbf{w})=\\mathbb{E}_{\\pi}\\left[\\left(q_{\\pi}(S, A)-\\hat{q}(S, A, \\mathbf{w})\\right)^{2}\\right]\\)<br></div><div><br></div><div>Use SGD to find a local minimum</div><div><br></div><div>\\(\\Delta \\mathbf{w}=\\alpha\\left(q_{\\pi}(S, A)-\\hat{q}(S, A, \\mathbf{w})\\right) \\nabla_{\\mathbf{w}} \\hat{q}(S, A, \\mathbf{w})\\)<br></div><div><br></div><div>For incremental control algorithms, we just substitute a target for&nbsp; \\(q_{\\pi}(S, A)\\)</div><div><br></div>"
                    ],
                    "guid": "c$OKZ?fyU4",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe the convergence of prediction algorithms",
                        "<img src=\"paste-cf477cc39d11ac2dfaec604081b6453e3f3aa572.jpg\">"
                    ],
                    "guid": "j[5J:b^iOQ",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe convergence of control algorithms",
                        "<img src=\"paste-61d50df17db1dbffa2363b27a829cdaaa0b8ff79.jpg\"><div>(tick) chatters around near-optimal value function<br></div>"
                    ],
                    "guid": "LBr!Jka{>[",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe least squares prediction as a batch method (RL)",
                        "<u>Given:</u>&nbsp;<div>A value function approximation&nbsp;\\(\\hat{v}(s, \\mathbf{w}) \\approx v_{\\pi}(s)\\)&nbsp;</div><div>and&nbsp;</div><div>experience \\(\\mathcal{D}\\) consisting of \\(\\langle state, value\\rangle \\) pairs</div><div>\\(\\mathcal{D}=\\left\\{\\left\\langle s_{1}, v_{1}^{\\pi}\\right\\rangle,\\left\\langle s_{2}, v_{2}^{\\pi}\\right\\rangle, \\dots,\\left\\langle s_{T}, v_{T}^{\\pi}\\right\\rangle\\right\\}\\)<br></div><div><br></div><div><u>Problem:</u></div><div> Which parameters \\(\\mathbf{w}\\) give the best fitting value fn \\(\\hat{v}(s, \\mathbf{w}) ?\\)</div><div><br></div><div><u>Solution:</u></div><div>Least squares algorithms find parameter vector&nbsp;\\(\\mathbf{w}\\) that minimises the sum-squared error between \\(\\hat{v}\\left(s_{t}, \\mathbf{w}\\right)\\) and target values \\(v_{t}^{\\pi}\\)&nbsp;</div><div><br></div><div>\\(\\begin{aligned} L S(\\mathbf{w}) &amp;=\\sum_{t=1}^{T}\\left(v_{t}^{\\pi}-\\hat{v}\\left(s_{t}, \\mathbf{w}\\right)\\right)^{2} \\\\ &amp;=\\mathbb{E}_{\\mathcal{D}}\\left[\\left(v^{\\pi}-\\hat{v}(s, \\mathbf{w})\\right)^{2}\\right] \\end{aligned}\\)<br></div>"
                    ],
                    "guid": "LS.$e?0Z;N",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe SGD with Experience Replay",
                        "Given experience consisting of \\(\\langle\\) state, value \\(\\rangle\\) pairs<br>\\(\\mathcal{D}=\\left\\{\\left\\langle s_{1}, v_{1}^{\\pi}\\right\\rangle,\\left\\langle s_{2}, v_{2}^{\\pi}\\right\\rangle, \\ldots,\\left\\langle s_{T}, v_{T}^{\\pi}\\right\\rangle\\right\\}\\)<div><br></div><div>Repeat:</div><div><br></div><div>1. Sample state, value pair from experience.&nbsp;\\(\\left\\langle s, v^{\\pi}\\right\\rangle \\sim \\mathcal{D}\\)</div><div>2. Apply SGD update,&nbsp;\\(\\Delta \\mathbf{w}=\\alpha\\left(v^{\\pi}-\\hat{v}(s, \\mathbf{w})\\right) \\nabla_{\\mathbf{w}} \\hat{v}(s, \\mathbf{w})\\)</div><div><br></div><div><br></div><div><b>Converges to LS solution</b></div><div>\\(\\mathbf{w}^{\\pi}=\\underset{\\mathbf{w}}{\\operatorname{argmin}} L S(\\mathbf{w})\\)<br></div>"
                    ],
                    "guid": "jxc%7+-?;p",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what are some disadvantages of policy based RL?",
                        "<b>Typically converge to a local rather than a global optimum</b><div><b><br></b></div><div><b>Evaluating a policy is typically ineffcient and high variance</b></div>"
                    ],
                    "guid": "Gj:DZCR~uL",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what is a policy objective function for?",
                        "Allow us to measure the quality of&nbsp;\\(\\pi_{\\theta}(s, a)\\)&nbsp;<div><br><div><div>\\(J_{a v R}(\\theta)=\\sum_{s} d^{\\pi_{\\theta}}(s) \\sum_{a} \\pi_{\\theta}(s, a) \\mathcal{R}_{s}^{a}\\)<br></div></div></div>"
                    ],
                    "guid": "qj6(WiMv}n",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "what do policy gradient algorithms do generally",
                        "Policy gradient algorithms find the local maxima of a policy objective function by ascending the gradient of the policy"
                    ],
                    "guid": "rFSv,+myQb",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "describe actor-critic algorithm, and give a simple algorithm.",
                        "<div>These algorithms maintain two sets of parameters</div><div><br></div><div><b>Critic: </b>Updates action-value function paramters <b>w </b>(helps reduce variance) (How good is policy \\(\\pi_{\\theta}\\) for current parameters \\(\\theta ?\\))</div><div><b>Actor:</b>&nbsp;Updates policy parameters&nbsp;<b>θ, </b>in direction of the critic</div><div><br></div><div><u>Simple Algo</u>:</div><div>Critic Updates \\(w\\) by linear TD(0)<br>Actor Updates \\(\\theta\\) by policy gradient<br></div><div><br></div><div><br></div><div><img src=\"paste-c62968e806545865e01281fa4a3381f1d7a29c4e.jpg\"><br></div><div><br></div><div><br></div><div><br></div>"
                    ],
                    "guid": "OrL4(=)Vw/",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are policy evaluation and policy improvement in tabular RL?",
                        "Policy evaluation:<div>compute the action value function<div><div>\\(Q^{\\pi}(s,a) = \\mathop{\\mathbb{E}}_{\\pi} \\left[ G_{t} \\vert S_{t} = s, A_{t} = a \\right] \\), where the expectation is over states visited under the policy \\(\\pi\\)</div></div><div><br></div><div>Policy improvement:</div><div>1. Policy evaluation for \\(\\pi\\) gives \\(Q^{\\pi}(s,a)\\),<br>2. Use this to obtain improved policy</div><div>\\(\\pi'(s,a) = \\mathop{\\mathrm{arg\\,max}}_{a} Q^{\\pi}(s,a).\\)</div></div><div>\\(\\Rightarrow \\pi' \\geq \\pi\\)</div><div><br></div><div>Repeate enough to find optimal \\(Q^*(s,a)\\)&nbsp;<br>(under some assumptions)</div>"
                    ],
                    "guid": "C<v=S]-Ux5",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                },
                {
                    "__type__": "Note",
                    "fields": [
                        "What are successor features in RL?",
                        "Write expected one-step reward \\(r\\) as<div>\\(r(s, a, s') = \\phi(s, a, s')^{T}\\mathbf{w},\\)</div><div>where \\(\\phi\\) and \\(\\mathbf{w}\\) are vectors in \\(\\mathbb{R}^{d}\\).</div><div><br></div><div>Then factorize the action value function:</div><div>\\(\\begin{align} Q^{\\pi}(s, a) &amp;= \\mathbb{E}_{\\pi} \\left[ \\sum_{i=t}^{\\infty} \\gamma^{i-t} r_{i+1} \\vert s_{t} = s, a_{t} = a \\right] \\\\ <br>&amp;= \\mathbf{\\phi}^{\\pi}(s,a)^{T} \\mathbf{w},\\\\<br>\\text{ with } \\mathbf{\\phi}^{\\pi}&amp;(s,a) \\equiv&nbsp;\\mathbb{E}_{\\pi} \\left[ \\sum_{i=t}^{\\infty} \\gamma^{i-t} \\phi_{i+1} \\vert s_{t} = s, a_{t} = a \\right]&nbsp;<br>\\end{align}\\)</div><div><br></div><div>\\( \\mathbf{\\phi}^{\\pi}(s,a) \\in \\mathbb{R}^{d}\\) are the successor features of \\((s, a)\\) under \\(\\pi\\)</div>"
                    ],
                    "guid": "dk/um/,%9X",
                    "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
                    "tags": []
                }
            ]
        }
    ],
    "crowdanki_uuid": "4277010a-7f79-11eb-a863-367dda5da221",
    "deck_config_uuid": "42770bf0-7f79-11eb-a863-367dda5da221",
    "deck_configurations": [
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "42770bf0-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "4277329c-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "42777644-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "4277cc48-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "4278497a-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "42786a36-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "427888c2-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "4278c15c-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "4279afa4-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "427a0544-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "427a3442-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        },
        {
            "__type__": "DeckConfig",
            "autoplay": true,
            "crowdanki_uuid": "427ae6a8-7f79-11eb-a863-367dda5da221",
            "dyn": false,
            "lapse": {
                "delays": [
                    10.0
                ],
                "leechAction": 0,
                "leechFails": 8,
                "minInt": 1,
                "mult": 0.0
            },
            "maxTaken": 60,
            "name": "Default",
            "new": {
                "bury": false,
                "delays": [
                    1.0,
                    10.0
                ],
                "initialFactor": 2500,
                "ints": [
                    1,
                    4,
                    0
                ],
                "order": 1,
                "perDay": 20,
                "separate": true
            },
            "replayq": true,
            "rev": {
                "bury": false,
                "ease4": 1.3,
                "fuzz": 0.05,
                "hardFactor": 1.2,
                "ivlFct": 1.0,
                "maxIvl": 36500,
                "minSpace": 1,
                "perDay": 200
            },
            "timer": 0
        }
    ],
    "desc": "",
    "dyn": 0,
    "extendNew": 63,
    "extendRev": 0,
    "media_files": [
        "Screen Shot 2021-03-06 at 11.03.22 AM.png"
    ],
    "name": "ml",
    "note_models": [
        {
            "__type__": "NoteModel",
            "crowdanki_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
            "css": ".card {\n font-family: arial;\n font-size: 20px;\n text-align: left;\n color: black;\n background-color: white;\n}\n",
            "flds": [
                {
                    "font": "Arial",
                    "media": [],
                    "name": "Front",
                    "ord": 0,
                    "rtl": false,
                    "size": 20,
                    "sticky": false
                },
                {
                    "font": "Arial",
                    "media": [],
                    "name": "Back",
                    "ord": 1,
                    "rtl": false,
                    "size": 20,
                    "sticky": false
                }
            ],
            "latexPost": "\\end{document}",
            "latexPre": "\\documentclass[12pt]{article}\n\\special{papersize=3in,5in}\n\\usepackage[utf8]{inputenc}\n\\usepackage{amssymb,amsmath}\n\\pagestyle{empty}\n\\setlength{\\parindent}{0in}\n\\begin{document}\n",
            "latexsvg": false,
            "name": "Basic",
            "req": [
                [
                    0,
                    "any",
                    [
                        0
                    ]
                ]
            ],
            "sortf": 0,
            "tags": [],
            "tmpls": [
                {
                    "afmt": "{{Front}}\n\n<hr id=answer>\n\n{{Back}}",
                    "bafmt": "",
                    "bfont": "",
                    "bqfmt": "",
                    "bsize": 0,
                    "did": null,
                    "name": "Card 1",
                    "ord": 0,
                    "qfmt": "{{Front}}"
                }
            ],
            "type": 0,
            "vers": []
        }
    ],
    "notes": [
        {
            "__type__": "Note",
            "fields": [
                "When can a matrix not be inverted?",
                "- Not square<div>- Basis of&nbsp; the matrix are linearly dependent</div>"
            ],
            "guid": "yK`yT7DiOQ",
            "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
            "tags": []
        },
        {
            "__type__": "Note",
            "fields": [
                "What is unrolling an RNN? Why do it?",
                "<div><img src=\"Screen Shot 2021-03-06 at 11.03.22 AM.png\"><br></div><div>Unrolling: explicitly represent each application of the RNN in the computation graph (using a fixed input length).</div><div><br></div><div>Big advantage: fixed sequence size.</div><div><br></div><div><div>We still end up learning a single model \\(A\\) that operates on all time steps and all sequence lengths.</div></div>"
            ],
            "guid": "KQW=[{_8DI",
            "note_model_uuid": "4277211c-7f79-11eb-a863-367dda5da221",
            "tags": []
        }
    ]
}